# SAGE Edge-Optimized Configuration
# Target: Jetson Orin Nano 8GB and similar edge devices
# Expected speedup: 40% (55s → 33s per question)
# Quality: Minimal degradation (<5%)

llm_irp:
  # Iteration settings (reduced for edge performance)
  irp_iterations: 3                    # Reduced from 5 (52% speedup validated)
  initial_temperature: 0.7              # Starting temperature for sampling
  min_temperature: 0.54                 # Minimum temperature (convergence)
  temp_reduction: 0.053                 # Proper 3-step annealing: (0.7-0.54)/3 = 0.053

  # Generation settings
  max_tokens: 150                       # Slightly reduced from 200

  # Early stopping (already optimal - no changes)
  energy_convergence_threshold: 0.1     # Halt if energy < 0.1
  energy_plateau_window: 3              # Check last 3 iterations
  energy_plateau_delta: 0.05            # Plateau if energies within 0.05

  # Memory management
  model_keep_alive: true                # Reuse loaded model (save 3.3s per session)
  max_memory_mb: 1200                   # Memory budget (942MB + 258MB headroom)

  # Device settings
  device: "cuda"                        # Use GPU acceleration
  precision: "fp16"                     # Half precision (could use int8 for 2x more speedup)

  # Edge-specific optimizations
  enable_thermal_monitoring: true       # Monitor Jetson temperature
  thermal_throttle_threshold: 85        # Throttle if temp > 85°C
  power_mode: "efficiency"              # Balance performance and power

snarc:
  # SNARC settings (overhead is negligible - no changes needed)
  salience_threshold: 0.15              # Capture threshold for memory
  dimensions:
    surprise: 0.20                      # Weight for surprise
    novelty: 0.20                       # Weight for novelty
    arousal: 0.20                       # Weight for arousal (perplexity)
    reward: 0.20                        # Weight for reward
    conflict: 0.20                      # Weight for conflict (paradox)

memory:
  # Memory configuration
  circular_buffer_size: 5               # Keep last 5 exchanges
  verbatim_storage: true                # Full-fidelity SQLite storage
  consolidation_interval: 100           # Consolidate every 100 exchanges

# Notes:
# - This configuration prioritizes speed while maintaining quality
# - Expected performance on Jetson Orin Nano:
#   - First question: ~36s (3.3s load + 33s inference)
#   - Subsequent: ~33s (model kept alive)
# - For even faster inference (~16-22s), implement INT8 quantization
# - For highest quality (slower), use default config with 5-7 iterations
