{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 146.16,
  "eval_steps": 500,
  "global_step": 1900,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.8,
      "grad_norm": 12.583158493041992,
      "learning_rate": 2.25e-06,
      "logits/chosen": -0.3918791711330414,
      "logits/rejected": 0.3666691184043884,
      "logps/chosen": -238.00936889648438,
      "logps/rejected": -185.06591796875,
      "loss": 0.6926,
      "rewards/accuracies": 0.30000001192092896,
      "rewards/chosen": 0.00019458775932434946,
      "rewards/margins": 0.0010565565899014473,
      "rewards/rejected": -0.0008619689615443349,
      "step": 10
    },
    {
      "epoch": 1.56,
      "grad_norm": 13.005526542663574,
      "learning_rate": 4.75e-06,
      "logits/chosen": -0.44152888655662537,
      "logits/rejected": 0.28866633772850037,
      "logps/chosen": -263.2706298828125,
      "logps/rejected": -185.21836853027344,
      "loss": 0.668,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.011780347675085068,
      "rewards/margins": 0.05278946831822395,
      "rewards/rejected": -0.04100911691784859,
      "step": 20
    },
    {
      "epoch": 2.32,
      "grad_norm": 12.239559173583984,
      "learning_rate": 4.982558139534885e-06,
      "logits/chosen": -0.03709470108151436,
      "logits/rejected": 0.6671642661094666,
      "logps/chosen": -287.8650817871094,
      "logps/rejected": -193.7211151123047,
      "loss": 0.6139,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03863581642508507,
      "rewards/margins": 0.1655617207288742,
      "rewards/rejected": -0.12692590057849884,
      "step": 30
    },
    {
      "epoch": 3.08,
      "grad_norm": 12.170333862304688,
      "learning_rate": 4.963178294573644e-06,
      "logits/chosen": -0.7361843585968018,
      "logits/rejected": 0.12678219377994537,
      "logps/chosen": -216.11317443847656,
      "logps/rejected": -180.3126220703125,
      "loss": 0.5439,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.08392731845378876,
      "rewards/margins": 0.328288733959198,
      "rewards/rejected": -0.24436140060424805,
      "step": 40
    },
    {
      "epoch": 3.88,
      "grad_norm": 9.26767635345459,
      "learning_rate": 4.943798449612404e-06,
      "logits/chosen": -0.41804489493370056,
      "logits/rejected": 0.36830830574035645,
      "logps/chosen": -240.5846710205078,
      "logps/rejected": -190.2620086669922,
      "loss": 0.4754,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1226980909705162,
      "rewards/margins": 0.4975948929786682,
      "rewards/rejected": -0.3748967945575714,
      "step": 50
    },
    {
      "epoch": 4.64,
      "grad_norm": 9.998600959777832,
      "learning_rate": 4.924418604651163e-06,
      "logits/chosen": -0.262810617685318,
      "logits/rejected": 0.51723712682724,
      "logps/chosen": -262.6007385253906,
      "logps/rejected": -190.02662658691406,
      "loss": 0.4134,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17613160610198975,
      "rewards/margins": 0.6766489148139954,
      "rewards/rejected": -0.5005173683166504,
      "step": 60
    },
    {
      "epoch": 5.4,
      "grad_norm": 7.033547401428223,
      "learning_rate": 4.905038759689923e-06,
      "logits/chosen": -0.7509766817092896,
      "logits/rejected": 0.10620131343603134,
      "logps/chosen": -224.08010864257812,
      "logps/rejected": -187.30123901367188,
      "loss": 0.3541,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21167677640914917,
      "rewards/margins": 0.863682210445404,
      "rewards/rejected": -0.6520053744316101,
      "step": 70
    },
    {
      "epoch": 6.16,
      "grad_norm": 7.660539627075195,
      "learning_rate": 4.8856589147286824e-06,
      "logits/chosen": -0.08820804953575134,
      "logits/rejected": 0.5782588720321655,
      "logps/chosen": -279.17926025390625,
      "logps/rejected": -201.4827880859375,
      "loss": 0.3084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21988850831985474,
      "rewards/margins": 1.029212474822998,
      "rewards/rejected": -0.8093240857124329,
      "step": 80
    },
    {
      "epoch": 6.96,
      "grad_norm": 5.4810943603515625,
      "learning_rate": 4.866279069767442e-06,
      "logits/chosen": -0.5880315899848938,
      "logits/rejected": 0.29113608598709106,
      "logps/chosen": -233.69955444335938,
      "logps/rejected": -190.21295166015625,
      "loss": 0.2491,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29681822657585144,
      "rewards/margins": 1.2745068073272705,
      "rewards/rejected": -0.9776886701583862,
      "step": 90
    },
    {
      "epoch": 7.72,
      "grad_norm": 7.084028720855713,
      "learning_rate": 4.846899224806202e-06,
      "logits/chosen": -0.5590221285820007,
      "logits/rejected": 0.32270658016204834,
      "logps/chosen": -235.56478881835938,
      "logps/rejected": -194.61695861816406,
      "loss": 0.2108,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31739652156829834,
      "rewards/margins": 1.4704519510269165,
      "rewards/rejected": -1.1530555486679077,
      "step": 100
    },
    {
      "epoch": 8.48,
      "grad_norm": 4.0411481857299805,
      "learning_rate": 4.827519379844961e-06,
      "logits/chosen": -0.3033892810344696,
      "logits/rejected": 0.37962496280670166,
      "logps/chosen": -265.8221740722656,
      "logps/rejected": -204.39208984375,
      "loss": 0.1559,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37859952449798584,
      "rewards/margins": 1.8115466833114624,
      "rewards/rejected": -1.4329472780227661,
      "step": 110
    },
    {
      "epoch": 9.24,
      "grad_norm": 3.7324562072753906,
      "learning_rate": 4.8081395348837216e-06,
      "logits/chosen": -0.6898423433303833,
      "logits/rejected": 0.2257736325263977,
      "logps/chosen": -218.24789428710938,
      "logps/rejected": -194.95179748535156,
      "loss": 0.1326,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3908310830593109,
      "rewards/margins": 2.0244476795196533,
      "rewards/rejected": -1.6336168050765991,
      "step": 120
    },
    {
      "epoch": 10.0,
      "grad_norm": 3.8691413402557373,
      "learning_rate": 4.788759689922481e-06,
      "logits/chosen": -0.2850496172904968,
      "logits/rejected": 0.43381956219673157,
      "logps/chosen": -268.5162048339844,
      "logps/rejected": -208.7872314453125,
      "loss": 0.1044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42606619000434875,
      "rewards/margins": 2.266934394836426,
      "rewards/rejected": -1.8408681154251099,
      "step": 130
    },
    {
      "epoch": 10.8,
      "grad_norm": 1.4989334344863892,
      "learning_rate": 4.769379844961241e-06,
      "logits/chosen": -0.6576435565948486,
      "logits/rejected": 0.23484604060649872,
      "logps/chosen": -228.41787719726562,
      "logps/rejected": -203.54515075683594,
      "loss": 0.0695,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4801756739616394,
      "rewards/margins": 2.749342679977417,
      "rewards/rejected": -2.269166946411133,
      "step": 140
    },
    {
      "epoch": 11.56,
      "grad_norm": 3.8616490364074707,
      "learning_rate": 4.75e-06,
      "logits/chosen": -0.00019828583754133433,
      "logits/rejected": 0.5225241780281067,
      "logps/chosen": -302.763671875,
      "logps/rejected": -221.03323364257812,
      "loss": 0.0545,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47247445583343506,
      "rewards/margins": 2.967161178588867,
      "rewards/rejected": -2.4946868419647217,
      "step": 150
    },
    {
      "epoch": 12.32,
      "grad_norm": 1.6952242851257324,
      "learning_rate": 4.73062015503876e-06,
      "logits/chosen": -0.8344181776046753,
      "logits/rejected": 0.10974018275737762,
      "logps/chosen": -214.80230712890625,
      "logps/rejected": -208.2884979248047,
      "loss": 0.0337,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5454131960868835,
      "rewards/margins": 3.5171806812286377,
      "rewards/rejected": -2.9717671871185303,
      "step": 160
    },
    {
      "epoch": 13.08,
      "grad_norm": 0.4981202185153961,
      "learning_rate": 4.71124031007752e-06,
      "logits/chosen": -0.5936597585678101,
      "logits/rejected": 0.18478959798812866,
      "logps/chosen": -240.64370727539062,
      "logps/rejected": -222.1982879638672,
      "loss": 0.0184,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.533107578754425,
      "rewards/margins": 4.115199089050293,
      "rewards/rejected": -3.5820915699005127,
      "step": 170
    },
    {
      "epoch": 13.88,
      "grad_norm": 0.5902432203292847,
      "learning_rate": 4.69186046511628e-06,
      "logits/chosen": -0.5257905721664429,
      "logits/rejected": 0.17323380708694458,
      "logps/chosen": -239.0926971435547,
      "logps/rejected": -223.62783813476562,
      "loss": 0.0159,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5296814441680908,
      "rewards/margins": 4.325718402862549,
      "rewards/rejected": -3.796036958694458,
      "step": 180
    },
    {
      "epoch": 14.64,
      "grad_norm": 0.3745081126689911,
      "learning_rate": 4.672480620155039e-06,
      "logits/chosen": -0.5361260175704956,
      "logits/rejected": 0.15544116497039795,
      "logps/chosen": -240.9336395263672,
      "logps/rejected": -227.60821533203125,
      "loss": 0.0082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6193750500679016,
      "rewards/margins": 4.978763580322266,
      "rewards/rejected": -4.359388828277588,
      "step": 190
    },
    {
      "epoch": 15.4,
      "grad_norm": 0.14544691145420074,
      "learning_rate": 4.653100775193799e-06,
      "logits/chosen": -0.8572344779968262,
      "logits/rejected": 0.009976930916309357,
      "logps/chosen": -231.48216247558594,
      "logps/rejected": -231.3031463623047,
      "loss": 0.008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5791990160942078,
      "rewards/margins": 5.310159683227539,
      "rewards/rejected": -4.730961322784424,
      "step": 200
    },
    {
      "epoch": 16.16,
      "grad_norm": 0.22327809035778046,
      "learning_rate": 4.6337209302325585e-06,
      "logits/chosen": -0.4261125326156616,
      "logits/rejected": 0.19862143695354462,
      "logps/chosen": -251.9224853515625,
      "logps/rejected": -232.5540771484375,
      "loss": 0.005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6547929048538208,
      "rewards/margins": 5.488130569458008,
      "rewards/rejected": -4.833337306976318,
      "step": 210
    },
    {
      "epoch": 16.96,
      "grad_norm": 0.09860511124134064,
      "learning_rate": 4.614341085271318e-06,
      "logits/chosen": -0.5091766119003296,
      "logits/rejected": 0.20546063780784607,
      "logps/chosen": -255.45419311523438,
      "logps/rejected": -240.2666015625,
      "loss": 0.0035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6168253421783447,
      "rewards/margins": 5.994416236877441,
      "rewards/rejected": -5.377591133117676,
      "step": 220
    },
    {
      "epoch": 17.72,
      "grad_norm": 0.1524442732334137,
      "learning_rate": 4.594961240310078e-06,
      "logits/chosen": -0.4662914276123047,
      "logits/rejected": 0.12273786216974258,
      "logps/chosen": -245.1249237060547,
      "logps/rejected": -244.98580932617188,
      "loss": 0.0023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6126425266265869,
      "rewards/margins": 6.393956184387207,
      "rewards/rejected": -5.781313419342041,
      "step": 230
    },
    {
      "epoch": 18.48,
      "grad_norm": 0.17460733652114868,
      "learning_rate": 4.575581395348837e-06,
      "logits/chosen": -0.947943925857544,
      "logits/rejected": -0.06600278615951538,
      "logps/chosen": -220.07801818847656,
      "logps/rejected": -241.3009033203125,
      "loss": 0.0022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6010103821754456,
      "rewards/margins": 6.608853340148926,
      "rewards/rejected": -6.007843017578125,
      "step": 240
    },
    {
      "epoch": 19.24,
      "grad_norm": 0.05763240158557892,
      "learning_rate": 4.556201550387598e-06,
      "logits/chosen": -0.5047527551651001,
      "logits/rejected": 0.06448230147361755,
      "logps/chosen": -256.536865234375,
      "logps/rejected": -248.09536743164062,
      "loss": 0.0015,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6885308623313904,
      "rewards/margins": 6.775704860687256,
      "rewards/rejected": -6.087173938751221,
      "step": 250
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.10613573342561722,
      "learning_rate": 4.536821705426357e-06,
      "logits/chosen": -0.38062378764152527,
      "logits/rejected": 0.1334618330001831,
      "logps/chosen": -256.0909729003906,
      "logps/rejected": -251.8834991455078,
      "loss": 0.0012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6427339315414429,
      "rewards/margins": 7.178643703460693,
      "rewards/rejected": -6.535909652709961,
      "step": 260
    },
    {
      "epoch": 20.8,
      "grad_norm": 0.08320729434490204,
      "learning_rate": 4.517441860465117e-06,
      "logits/chosen": -0.4306275248527527,
      "logits/rejected": 0.08380306512117386,
      "logps/chosen": -260.79937744140625,
      "logps/rejected": -252.9586944580078,
      "loss": 0.0009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6697593331336975,
      "rewards/margins": 7.362252712249756,
      "rewards/rejected": -6.692493438720703,
      "step": 270
    },
    {
      "epoch": 21.56,
      "grad_norm": 0.01673377864062786,
      "learning_rate": 4.498062015503876e-06,
      "logits/chosen": -0.7233220934867859,
      "logits/rejected": -0.08028516918420792,
      "logps/chosen": -237.35690307617188,
      "logps/rejected": -257.46441650390625,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6654757261276245,
      "rewards/margins": 7.800344467163086,
      "rewards/rejected": -7.134868621826172,
      "step": 280
    },
    {
      "epoch": 22.32,
      "grad_norm": 0.07048825919628143,
      "learning_rate": 4.478682170542636e-06,
      "logits/chosen": -0.29158490896224976,
      "logits/rejected": 0.12493979185819626,
      "logps/chosen": -265.1695251464844,
      "logps/rejected": -257.7008972167969,
      "loss": 0.0007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6331345438957214,
      "rewards/margins": 7.560375213623047,
      "rewards/rejected": -6.927240371704102,
      "step": 290
    },
    {
      "epoch": 23.08,
      "grad_norm": 0.010636817663908005,
      "learning_rate": 4.4593023255813955e-06,
      "logits/chosen": -1.105890154838562,
      "logits/rejected": -0.3916129171848297,
      "logps/chosen": -200.5428466796875,
      "logps/rejected": -258.61651611328125,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6227915287017822,
      "rewards/margins": 8.682502746582031,
      "rewards/rejected": -8.059711456298828,
      "step": 300
    },
    {
      "epoch": 23.88,
      "grad_norm": 0.04542082920670509,
      "learning_rate": 4.439922480620155e-06,
      "logits/chosen": -0.4476284384727478,
      "logits/rejected": -0.01572706177830696,
      "logps/chosen": -258.0579833984375,
      "logps/rejected": -263.19964599609375,
      "loss": 0.0005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6867944598197937,
      "rewards/margins": 8.249730110168457,
      "rewards/rejected": -7.562935829162598,
      "step": 310
    },
    {
      "epoch": 24.64,
      "grad_norm": 0.02563062496483326,
      "learning_rate": 4.420542635658915e-06,
      "logits/chosen": -0.41085678339004517,
      "logits/rejected": 0.027747511863708496,
      "logps/chosen": -259.18463134765625,
      "logps/rejected": -260.2064208984375,
      "loss": 0.0004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6291744112968445,
      "rewards/margins": 8.224532127380371,
      "rewards/rejected": -7.595357894897461,
      "step": 320
    },
    {
      "epoch": 25.4,
      "grad_norm": 0.015858059749007225,
      "learning_rate": 4.401162790697675e-06,
      "logits/chosen": -0.9225795269012451,
      "logits/rejected": -0.33237046003341675,
      "logps/chosen": -225.14170837402344,
      "logps/rejected": -271.1098327636719,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6307703256607056,
      "rewards/margins": 9.065704345703125,
      "rewards/rejected": -8.43493366241455,
      "step": 330
    },
    {
      "epoch": 26.16,
      "grad_norm": 0.004861758556216955,
      "learning_rate": 4.3817829457364346e-06,
      "logits/chosen": -0.6562058329582214,
      "logits/rejected": -0.23487462103366852,
      "logps/chosen": -234.71762084960938,
      "logps/rejected": -267.631103515625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6598559021949768,
      "rewards/margins": 9.105313301086426,
      "rewards/rejected": -8.445457458496094,
      "step": 340
    },
    {
      "epoch": 26.96,
      "grad_norm": 0.0414411760866642,
      "learning_rate": 4.362403100775194e-06,
      "logits/chosen": -0.4594024121761322,
      "logits/rejected": -0.0841352790594101,
      "logps/chosen": -248.95773315429688,
      "logps/rejected": -268.0075988769531,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6672235727310181,
      "rewards/margins": 8.918683052062988,
      "rewards/rejected": -8.251459121704102,
      "step": 350
    },
    {
      "epoch": 27.72,
      "grad_norm": 0.024184348061680794,
      "learning_rate": 4.343023255813954e-06,
      "logits/chosen": -0.5387914776802063,
      "logits/rejected": -0.18912385404109955,
      "logps/chosen": -246.5767822265625,
      "logps/rejected": -275.3699035644531,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6415599584579468,
      "rewards/margins": 9.313041687011719,
      "rewards/rejected": -8.671481132507324,
      "step": 360
    },
    {
      "epoch": 28.48,
      "grad_norm": 0.009896116331219673,
      "learning_rate": 4.323643410852713e-06,
      "logits/chosen": -0.9145447611808777,
      "logits/rejected": -0.3095214366912842,
      "logps/chosen": -237.4842529296875,
      "logps/rejected": -269.420654296875,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6431933045387268,
      "rewards/margins": 9.652026176452637,
      "rewards/rejected": -9.008831977844238,
      "step": 370
    },
    {
      "epoch": 29.24,
      "grad_norm": 0.0498524084687233,
      "learning_rate": 4.304263565891474e-06,
      "logits/chosen": -0.11940092593431473,
      "logits/rejected": -0.002465825295075774,
      "logps/chosen": -260.71405029296875,
      "logps/rejected": -273.8292541503906,
      "loss": 0.0003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6684424877166748,
      "rewards/margins": 8.85916519165039,
      "rewards/rejected": -8.190722465515137,
      "step": 380
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.14618755877017975,
      "learning_rate": 4.284883720930233e-06,
      "logits/chosen": -0.7884126305580139,
      "logits/rejected": -0.3030409514904022,
      "logps/chosen": -237.06809997558594,
      "logps/rejected": -275.1368408203125,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.658046305179596,
      "rewards/margins": 9.937952995300293,
      "rewards/rejected": -9.2799072265625,
      "step": 390
    },
    {
      "epoch": 30.8,
      "grad_norm": 0.01762418821454048,
      "learning_rate": 4.265503875968993e-06,
      "logits/chosen": -0.6580569744110107,
      "logits/rejected": -0.25707367062568665,
      "logps/chosen": -244.5819091796875,
      "logps/rejected": -277.7809753417969,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6764260530471802,
      "rewards/margins": 9.869229316711426,
      "rewards/rejected": -9.192804336547852,
      "step": 400
    },
    {
      "epoch": 31.56,
      "grad_norm": 0.005082160700112581,
      "learning_rate": 4.246124031007752e-06,
      "logits/chosen": -0.7506895661354065,
      "logits/rejected": -0.3369397819042206,
      "logps/chosen": -223.2030792236328,
      "logps/rejected": -271.46392822265625,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6188749670982361,
      "rewards/margins": 9.818479537963867,
      "rewards/rejected": -9.199605941772461,
      "step": 410
    },
    {
      "epoch": 32.32,
      "grad_norm": 0.00325837847776711,
      "learning_rate": 4.226744186046512e-06,
      "logits/chosen": -0.351554274559021,
      "logits/rejected": -0.21167831122875214,
      "logps/chosen": -268.37225341796875,
      "logps/rejected": -287.6729431152344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6644962430000305,
      "rewards/margins": 10.110121726989746,
      "rewards/rejected": -9.445626258850098,
      "step": 420
    },
    {
      "epoch": 33.08,
      "grad_norm": 0.0026330742985010147,
      "learning_rate": 4.2073643410852715e-06,
      "logits/chosen": -0.7801709175109863,
      "logits/rejected": -0.2700660228729248,
      "logps/chosen": -235.7330322265625,
      "logps/rejected": -273.34722900390625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6877509951591492,
      "rewards/margins": 9.998295783996582,
      "rewards/rejected": -9.310544967651367,
      "step": 430
    },
    {
      "epoch": 33.88,
      "grad_norm": 0.013991341926157475,
      "learning_rate": 4.187984496124031e-06,
      "logits/chosen": -0.3161698579788208,
      "logits/rejected": -0.09248531609773636,
      "logps/chosen": -263.8036804199219,
      "logps/rejected": -280.2079162597656,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6465528607368469,
      "rewards/margins": 9.792938232421875,
      "rewards/rejected": -9.146385192871094,
      "step": 440
    },
    {
      "epoch": 34.64,
      "grad_norm": 0.003137070219963789,
      "learning_rate": 4.168604651162791e-06,
      "logits/chosen": -0.7372638583183289,
      "logits/rejected": -0.4032727777957916,
      "logps/chosen": -232.0170440673828,
      "logps/rejected": -286.908447265625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6414373517036438,
      "rewards/margins": 10.533658027648926,
      "rewards/rejected": -9.892221450805664,
      "step": 450
    },
    {
      "epoch": 35.4,
      "grad_norm": 0.002100817859172821,
      "learning_rate": 4.14922480620155e-06,
      "logits/chosen": -0.7264059782028198,
      "logits/rejected": -0.28909963369369507,
      "logps/chosen": -226.3368682861328,
      "logps/rejected": -275.7672119140625,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6453946828842163,
      "rewards/margins": 10.461472511291504,
      "rewards/rejected": -9.816078186035156,
      "step": 460
    },
    {
      "epoch": 36.16,
      "grad_norm": 0.002202172763645649,
      "learning_rate": 4.12984496124031e-06,
      "logits/chosen": -0.5719805955886841,
      "logits/rejected": -0.2788234055042267,
      "logps/chosen": -255.67930603027344,
      "logps/rejected": -282.7718505859375,
      "loss": 0.0002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6866887211799622,
      "rewards/margins": 10.108181953430176,
      "rewards/rejected": -9.421492576599121,
      "step": 470
    },
    {
      "epoch": 36.96,
      "grad_norm": 0.0025273640640079975,
      "learning_rate": 4.11046511627907e-06,
      "logits/chosen": -0.5119827389717102,
      "logits/rejected": -0.2525639533996582,
      "logps/chosen": -249.77682495117188,
      "logps/rejected": -284.9070739746094,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6362627744674683,
      "rewards/margins": 10.431591033935547,
      "rewards/rejected": -9.795328140258789,
      "step": 480
    },
    {
      "epoch": 37.72,
      "grad_norm": 0.01906275935471058,
      "learning_rate": 4.09108527131783e-06,
      "logits/chosen": -0.4871540069580078,
      "logits/rejected": -0.21451447904109955,
      "logps/chosen": -256.58990478515625,
      "logps/rejected": -282.7973327636719,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6534438729286194,
      "rewards/margins": 10.510618209838867,
      "rewards/rejected": -9.85717487335205,
      "step": 490
    },
    {
      "epoch": 38.48,
      "grad_norm": 0.00992876198142767,
      "learning_rate": 4.071705426356589e-06,
      "logits/chosen": -0.8973221182823181,
      "logits/rejected": -0.47379744052886963,
      "logps/chosen": -216.27403259277344,
      "logps/rejected": -287.5682678222656,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6111671328544617,
      "rewards/margins": 10.766841888427734,
      "rewards/rejected": -10.155675888061523,
      "step": 500
    },
    {
      "epoch": 39.24,
      "grad_norm": 0.0025977767072618008,
      "learning_rate": 4.05232558139535e-06,
      "logits/chosen": -0.4546978175640106,
      "logits/rejected": -0.18466806411743164,
      "logps/chosen": -266.91900634765625,
      "logps/rejected": -283.44989013671875,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7404453158378601,
      "rewards/margins": 10.606941223144531,
      "rewards/rejected": -9.866497039794922,
      "step": 510
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.013455529697239399,
      "learning_rate": 4.032945736434109e-06,
      "logits/chosen": -0.6472468376159668,
      "logits/rejected": -0.35522696375846863,
      "logps/chosen": -232.35047912597656,
      "logps/rejected": -284.0682678222656,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6348831057548523,
      "rewards/margins": 10.609722137451172,
      "rewards/rejected": -9.974838256835938,
      "step": 520
    },
    {
      "epoch": 40.8,
      "grad_norm": 0.0014267077203840017,
      "learning_rate": 4.013565891472869e-06,
      "logits/chosen": -0.5726728439331055,
      "logits/rejected": -0.3277845084667206,
      "logps/chosen": -237.673095703125,
      "logps/rejected": -289.26934814453125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6337906718254089,
      "rewards/margins": 10.83273983001709,
      "rewards/rejected": -10.198949813842773,
      "step": 530
    },
    {
      "epoch": 41.56,
      "grad_norm": 0.007009509950876236,
      "learning_rate": 3.9941860465116285e-06,
      "logits/chosen": -0.7856123447418213,
      "logits/rejected": -0.3992522358894348,
      "logps/chosen": -244.04833984375,
      "logps/rejected": -285.1640625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7195626497268677,
      "rewards/margins": 10.962817192077637,
      "rewards/rejected": -10.243253707885742,
      "step": 540
    },
    {
      "epoch": 42.32,
      "grad_norm": 0.005436422768980265,
      "learning_rate": 3.974806201550388e-06,
      "logits/chosen": -0.49930211901664734,
      "logits/rejected": -0.254256933927536,
      "logps/chosen": -253.0786590576172,
      "logps/rejected": -283.4512023925781,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6753489375114441,
      "rewards/margins": 10.466545104980469,
      "rewards/rejected": -9.7911958694458,
      "step": 550
    },
    {
      "epoch": 43.08,
      "grad_norm": 0.0004087052948307246,
      "learning_rate": 3.955426356589148e-06,
      "logits/chosen": -0.7304011583328247,
      "logits/rejected": -0.39826762676239014,
      "logps/chosen": -233.7836456298828,
      "logps/rejected": -290.3819274902344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6167905330657959,
      "rewards/margins": 11.349909782409668,
      "rewards/rejected": -10.733119010925293,
      "step": 560
    },
    {
      "epoch": 43.88,
      "grad_norm": 0.016277076676487923,
      "learning_rate": 3.936046511627907e-06,
      "logits/chosen": -0.5832553505897522,
      "logits/rejected": -0.3245680332183838,
      "logps/chosen": -236.4794464111328,
      "logps/rejected": -288.61474609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6301615834236145,
      "rewards/margins": 10.990803718566895,
      "rewards/rejected": -10.360642433166504,
      "step": 570
    },
    {
      "epoch": 44.64,
      "grad_norm": 0.0055106813088059425,
      "learning_rate": 3.916666666666667e-06,
      "logits/chosen": -0.44260090589523315,
      "logits/rejected": -0.2027062624692917,
      "logps/chosen": -257.5625915527344,
      "logps/rejected": -290.3815612792969,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6489356756210327,
      "rewards/margins": 10.745999336242676,
      "rewards/rejected": -10.097064018249512,
      "step": 580
    },
    {
      "epoch": 45.4,
      "grad_norm": 0.010849031619727612,
      "learning_rate": 3.897286821705426e-06,
      "logits/chosen": -0.7093527913093567,
      "logits/rejected": -0.46928316354751587,
      "logps/chosen": -241.01817321777344,
      "logps/rejected": -289.48419189453125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6531676650047302,
      "rewards/margins": 11.158268928527832,
      "rewards/rejected": -10.505102157592773,
      "step": 590
    },
    {
      "epoch": 46.16,
      "grad_norm": 0.0011374005116522312,
      "learning_rate": 3.877906976744186e-06,
      "logits/chosen": -0.6047070622444153,
      "logits/rejected": -0.27674761414527893,
      "logps/chosen": -242.20677185058594,
      "logps/rejected": -287.11602783203125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6974669098854065,
      "rewards/margins": 11.083321571350098,
      "rewards/rejected": -10.385855674743652,
      "step": 600
    },
    {
      "epoch": 46.96,
      "grad_norm": 0.0005992710357531905,
      "learning_rate": 3.858527131782946e-06,
      "logits/chosen": -0.5035576820373535,
      "logits/rejected": -0.29876771569252014,
      "logps/chosen": -253.49758911132812,
      "logps/rejected": -290.0664367675781,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6753718852996826,
      "rewards/margins": 11.102323532104492,
      "rewards/rejected": -10.42695140838623,
      "step": 610
    },
    {
      "epoch": 47.72,
      "grad_norm": 0.009038154035806656,
      "learning_rate": 3.839147286821706e-06,
      "logits/chosen": -0.5615381002426147,
      "logits/rejected": -0.30721673369407654,
      "logps/chosen": -245.2345733642578,
      "logps/rejected": -295.7298889160156,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6174027323722839,
      "rewards/margins": 11.07377815246582,
      "rewards/rejected": -10.456375122070312,
      "step": 620
    },
    {
      "epoch": 48.48,
      "grad_norm": 0.03602265939116478,
      "learning_rate": 3.819767441860465e-06,
      "logits/chosen": -0.6782679557800293,
      "logits/rejected": -0.4133780002593994,
      "logps/chosen": -240.6033172607422,
      "logps/rejected": -287.7655334472656,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7199125289916992,
      "rewards/margins": 11.381033897399902,
      "rewards/rejected": -10.66112232208252,
      "step": 630
    },
    {
      "epoch": 49.24,
      "grad_norm": 0.010847159661352634,
      "learning_rate": 3.800387596899225e-06,
      "logits/chosen": -0.6483569145202637,
      "logits/rejected": -0.29411497712135315,
      "logps/chosen": -254.0657958984375,
      "logps/rejected": -287.57904052734375,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6574897766113281,
      "rewards/margins": 11.085848808288574,
      "rewards/rejected": -10.428359985351562,
      "step": 640
    },
    {
      "epoch": 50.0,
      "grad_norm": 0.0008065024157986045,
      "learning_rate": 3.781007751937985e-06,
      "logits/chosen": -0.5925728678703308,
      "logits/rejected": -0.38465583324432373,
      "logps/chosen": -233.576171875,
      "logps/rejected": -295.0184020996094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6409916281700134,
      "rewards/margins": 11.540133476257324,
      "rewards/rejected": -10.899142265319824,
      "step": 650
    },
    {
      "epoch": 50.8,
      "grad_norm": 0.0006614364101551473,
      "learning_rate": 3.761627906976745e-06,
      "logits/chosen": -0.6968543529510498,
      "logits/rejected": -0.42891231179237366,
      "logps/chosen": -234.30972290039062,
      "logps/rejected": -297.10052490234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6338017582893372,
      "rewards/margins": 11.820834159851074,
      "rewards/rejected": -11.187032699584961,
      "step": 660
    },
    {
      "epoch": 51.56,
      "grad_norm": 0.003801609855145216,
      "learning_rate": 3.7422480620155045e-06,
      "logits/chosen": -0.4508896768093109,
      "logits/rejected": -0.23851804435253143,
      "logps/chosen": -258.2494812011719,
      "logps/rejected": -285.516845703125,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6774688959121704,
      "rewards/margins": 10.561938285827637,
      "rewards/rejected": -9.884468078613281,
      "step": 670
    },
    {
      "epoch": 52.32,
      "grad_norm": 0.005048881750553846,
      "learning_rate": 3.722868217054264e-06,
      "logits/chosen": -0.544858455657959,
      "logits/rejected": -0.33328473567962646,
      "logps/chosen": -244.4427490234375,
      "logps/rejected": -299.9119567871094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6334813237190247,
      "rewards/margins": 11.834132194519043,
      "rewards/rejected": -11.200650215148926,
      "step": 680
    },
    {
      "epoch": 53.08,
      "grad_norm": 0.0004616989754140377,
      "learning_rate": 3.7034883720930236e-06,
      "logits/chosen": -0.8020517826080322,
      "logits/rejected": -0.4575168192386627,
      "logps/chosen": -228.2918701171875,
      "logps/rejected": -288.1029357910156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7062405347824097,
      "rewards/margins": 11.611544609069824,
      "rewards/rejected": -10.905303001403809,
      "step": 690
    },
    {
      "epoch": 53.88,
      "grad_norm": 0.0003601940115913749,
      "learning_rate": 3.6841085271317832e-06,
      "logits/chosen": -0.5420640707015991,
      "logits/rejected": -0.297267347574234,
      "logps/chosen": -252.86328125,
      "logps/rejected": -293.10809326171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6818572878837585,
      "rewards/margins": 11.38032054901123,
      "rewards/rejected": -10.69846248626709,
      "step": 700
    },
    {
      "epoch": 54.64,
      "grad_norm": 0.00026841636281460524,
      "learning_rate": 3.664728682170543e-06,
      "logits/chosen": -0.7655791640281677,
      "logits/rejected": -0.47024691104888916,
      "logps/chosen": -234.2257080078125,
      "logps/rejected": -295.2640686035156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6549066305160522,
      "rewards/margins": 11.755831718444824,
      "rewards/rejected": -11.10092544555664,
      "step": 710
    },
    {
      "epoch": 55.4,
      "grad_norm": 0.0021858043037354946,
      "learning_rate": 3.6453488372093028e-06,
      "logits/chosen": -0.12104282528162003,
      "logits/rejected": -0.175606369972229,
      "logps/chosen": -284.87933349609375,
      "logps/rejected": -300.9985046386719,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6535188555717468,
      "rewards/margins": 11.42012882232666,
      "rewards/rejected": -10.766611099243164,
      "step": 720
    },
    {
      "epoch": 56.16,
      "grad_norm": 0.0024954366963356733,
      "learning_rate": 3.6259689922480623e-06,
      "logits/chosen": -0.9720517992973328,
      "logits/rejected": -0.4949185848236084,
      "logps/chosen": -216.35546875,
      "logps/rejected": -289.8634948730469,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6654005646705627,
      "rewards/margins": 11.684244155883789,
      "rewards/rejected": -11.018843650817871,
      "step": 730
    },
    {
      "epoch": 56.96,
      "grad_norm": 0.0016480983467772603,
      "learning_rate": 3.606589147286822e-06,
      "logits/chosen": -0.6356991529464722,
      "logits/rejected": -0.39383095502853394,
      "logps/chosen": -238.5413818359375,
      "logps/rejected": -294.2767333984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6637527346611023,
      "rewards/margins": 11.658418655395508,
      "rewards/rejected": -10.994665145874023,
      "step": 740
    },
    {
      "epoch": 57.72,
      "grad_norm": 0.0011394631583243608,
      "learning_rate": 3.5872093023255815e-06,
      "logits/chosen": -0.6494965553283691,
      "logits/rejected": -0.42159155011177063,
      "logps/chosen": -241.90643310546875,
      "logps/rejected": -293.1517639160156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6882097721099854,
      "rewards/margins": 11.700417518615723,
      "rewards/rejected": -11.01220989227295,
      "step": 750
    },
    {
      "epoch": 58.48,
      "grad_norm": 0.005230383947491646,
      "learning_rate": 3.5678294573643415e-06,
      "logits/chosen": -0.5676191449165344,
      "logits/rejected": -0.358822226524353,
      "logps/chosen": -258.544189453125,
      "logps/rejected": -294.8213806152344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6516839861869812,
      "rewards/margins": 11.472341537475586,
      "rewards/rejected": -10.820659637451172,
      "step": 760
    },
    {
      "epoch": 59.24,
      "grad_norm": 0.0021667631808668375,
      "learning_rate": 3.548449612403101e-06,
      "logits/chosen": -0.4240773916244507,
      "logits/rejected": -0.2992537319660187,
      "logps/chosen": -238.0612335205078,
      "logps/rejected": -304.6588134765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6085447072982788,
      "rewards/margins": 12.127134323120117,
      "rewards/rejected": -11.51858901977539,
      "step": 770
    },
    {
      "epoch": 60.0,
      "grad_norm": 0.008240833878517151,
      "learning_rate": 3.5290697674418606e-06,
      "logits/chosen": -0.7481958270072937,
      "logits/rejected": -0.4171999990940094,
      "logps/chosen": -241.85035705566406,
      "logps/rejected": -290.707763671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7062957882881165,
      "rewards/margins": 11.518437385559082,
      "rewards/rejected": -10.812141418457031,
      "step": 780
    },
    {
      "epoch": 60.8,
      "grad_norm": 0.0011992729268968105,
      "learning_rate": 3.50968992248062e-06,
      "logits/chosen": -0.5697044134140015,
      "logits/rejected": -0.38346606492996216,
      "logps/chosen": -243.5030975341797,
      "logps/rejected": -297.13543701171875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6626163125038147,
      "rewards/margins": 11.723505020141602,
      "rewards/rejected": -11.06088924407959,
      "step": 790
    },
    {
      "epoch": 61.56,
      "grad_norm": 0.003990884404629469,
      "learning_rate": 3.4903100775193797e-06,
      "logits/chosen": -0.6892026662826538,
      "logits/rejected": -0.3793465495109558,
      "logps/chosen": -237.58743286132812,
      "logps/rejected": -299.5990295410156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6530548930168152,
      "rewards/margins": 12.165167808532715,
      "rewards/rejected": -11.512113571166992,
      "step": 800
    },
    {
      "epoch": 62.32,
      "grad_norm": 0.004953681956976652,
      "learning_rate": 3.4709302325581397e-06,
      "logits/chosen": -0.6501618027687073,
      "logits/rejected": -0.42969512939453125,
      "logps/chosen": -249.16612243652344,
      "logps/rejected": -296.1665344238281,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.649347186088562,
      "rewards/margins": 11.543996810913086,
      "rewards/rejected": -10.894649505615234,
      "step": 810
    },
    {
      "epoch": 63.08,
      "grad_norm": 0.003861841280013323,
      "learning_rate": 3.4515503875968997e-06,
      "logits/chosen": -0.4267503321170807,
      "logits/rejected": -0.3095565140247345,
      "logps/chosen": -249.80247497558594,
      "logps/rejected": -295.1600341796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6899593472480774,
      "rewards/margins": 11.9083890914917,
      "rewards/rejected": -11.218430519104004,
      "step": 820
    },
    {
      "epoch": 63.88,
      "grad_norm": 0.004566439427435398,
      "learning_rate": 3.4321705426356593e-06,
      "logits/chosen": -0.4932953417301178,
      "logits/rejected": -0.2750850021839142,
      "logps/chosen": -254.0644073486328,
      "logps/rejected": -296.6524658203125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6834194660186768,
      "rewards/margins": 11.784689903259277,
      "rewards/rejected": -11.10127067565918,
      "step": 830
    },
    {
      "epoch": 64.64,
      "grad_norm": 0.004143290221691132,
      "learning_rate": 3.4127906976744193e-06,
      "logits/chosen": -0.9815848469734192,
      "logits/rejected": -0.6109076142311096,
      "logps/chosen": -213.28643798828125,
      "logps/rejected": -300.2609558105469,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6210923194885254,
      "rewards/margins": 12.330085754394531,
      "rewards/rejected": -11.708992958068848,
      "step": 840
    },
    {
      "epoch": 65.4,
      "grad_norm": 0.0013272898504510522,
      "learning_rate": 3.393410852713179e-06,
      "logits/chosen": -0.4024162292480469,
      "logits/rejected": -0.2855435311794281,
      "logps/chosen": -265.3989562988281,
      "logps/rejected": -294.7344665527344,
      "loss": 0.0001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6997707486152649,
      "rewards/margins": 11.545909881591797,
      "rewards/rejected": -10.846138954162598,
      "step": 850
    },
    {
      "epoch": 66.16,
      "grad_norm": 0.0014923294074833393,
      "learning_rate": 3.3740310077519384e-06,
      "logits/chosen": -0.5064702033996582,
      "logits/rejected": -0.364219069480896,
      "logps/chosen": -252.78099060058594,
      "logps/rejected": -299.5602722167969,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6285693645477295,
      "rewards/margins": 11.976912498474121,
      "rewards/rejected": -11.348344802856445,
      "step": 860
    },
    {
      "epoch": 66.96,
      "grad_norm": 0.0004398876626510173,
      "learning_rate": 3.354651162790698e-06,
      "logits/chosen": -0.8248205184936523,
      "logits/rejected": -0.49571818113327026,
      "logps/chosen": -227.34799194335938,
      "logps/rejected": -299.29522705078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7019265294075012,
      "rewards/margins": 12.185572624206543,
      "rewards/rejected": -11.483646392822266,
      "step": 870
    },
    {
      "epoch": 67.72,
      "grad_norm": 0.0006344637367874384,
      "learning_rate": 3.3352713178294575e-06,
      "logits/chosen": -0.5467288494110107,
      "logits/rejected": -0.39700281620025635,
      "logps/chosen": -237.62026977539062,
      "logps/rejected": -302.1635437011719,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5988590717315674,
      "rewards/margins": 12.025616645812988,
      "rewards/rejected": -11.4267578125,
      "step": 880
    },
    {
      "epoch": 68.48,
      "grad_norm": 0.0010373328113928437,
      "learning_rate": 3.3158914728682175e-06,
      "logits/chosen": -0.7637822031974792,
      "logits/rejected": -0.453144371509552,
      "logps/chosen": -252.3505859375,
      "logps/rejected": -290.839599609375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7598292827606201,
      "rewards/margins": 12.0175199508667,
      "rewards/rejected": -11.2576904296875,
      "step": 890
    },
    {
      "epoch": 69.24,
      "grad_norm": 0.0014920479152351618,
      "learning_rate": 3.296511627906977e-06,
      "logits/chosen": -0.5471696853637695,
      "logits/rejected": -0.3568201959133148,
      "logps/chosen": -240.69583129882812,
      "logps/rejected": -303.8086853027344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5942535996437073,
      "rewards/margins": 12.07250690460205,
      "rewards/rejected": -11.478252410888672,
      "step": 900
    },
    {
      "epoch": 70.0,
      "grad_norm": 0.0005447235889732838,
      "learning_rate": 3.2771317829457367e-06,
      "logits/chosen": -0.5319730639457703,
      "logits/rejected": -0.3462759554386139,
      "logps/chosen": -248.78199768066406,
      "logps/rejected": -299.4017028808594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6965270638465881,
      "rewards/margins": 12.014366149902344,
      "rewards/rejected": -11.317838668823242,
      "step": 910
    },
    {
      "epoch": 70.8,
      "grad_norm": 0.0007673998479731381,
      "learning_rate": 3.2577519379844962e-06,
      "logits/chosen": -0.607434868812561,
      "logits/rejected": -0.4016907811164856,
      "logps/chosen": -255.78121948242188,
      "logps/rejected": -300.7461853027344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6971664428710938,
      "rewards/margins": 12.033373832702637,
      "rewards/rejected": -11.33620834350586,
      "step": 920
    },
    {
      "epoch": 71.56,
      "grad_norm": 0.00028106546960771084,
      "learning_rate": 3.238372093023256e-06,
      "logits/chosen": -0.6246219873428345,
      "logits/rejected": -0.4174058437347412,
      "logps/chosen": -224.4740447998047,
      "logps/rejected": -296.1198425292969,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5997433662414551,
      "rewards/margins": 12.063972473144531,
      "rewards/rejected": -11.464228630065918,
      "step": 930
    },
    {
      "epoch": 72.32,
      "grad_norm": 0.0006606602692045271,
      "learning_rate": 3.2189922480620158e-06,
      "logits/chosen": -0.4991007447242737,
      "logits/rejected": -0.3672870695590973,
      "logps/chosen": -252.98483276367188,
      "logps/rejected": -306.2326354980469,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6917607188224792,
      "rewards/margins": 12.42007827758789,
      "rewards/rejected": -11.728318214416504,
      "step": 940
    },
    {
      "epoch": 73.08,
      "grad_norm": 0.006903102621436119,
      "learning_rate": 3.1996124031007754e-06,
      "logits/chosen": -0.742543637752533,
      "logits/rejected": -0.44951558113098145,
      "logps/chosen": -233.06712341308594,
      "logps/rejected": -291.8909912109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.662766695022583,
      "rewards/margins": 11.775300979614258,
      "rewards/rejected": -11.112534523010254,
      "step": 950
    },
    {
      "epoch": 73.88,
      "grad_norm": 0.0011624780017882586,
      "learning_rate": 3.180232558139535e-06,
      "logits/chosen": -0.5432482957839966,
      "logits/rejected": -0.3786035180091858,
      "logps/chosen": -258.11663818359375,
      "logps/rejected": -302.67510986328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6884268522262573,
      "rewards/margins": 12.287798881530762,
      "rewards/rejected": -11.599371910095215,
      "step": 960
    },
    {
      "epoch": 74.64,
      "grad_norm": 0.0009628721163608134,
      "learning_rate": 3.1608527131782945e-06,
      "logits/chosen": -0.5738251805305481,
      "logits/rejected": -0.36821532249450684,
      "logps/chosen": -243.2089080810547,
      "logps/rejected": -306.4656677246094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6237524151802063,
      "rewards/margins": 12.557299613952637,
      "rewards/rejected": -11.933548927307129,
      "step": 970
    },
    {
      "epoch": 75.4,
      "grad_norm": 0.003523625899106264,
      "learning_rate": 3.141472868217055e-06,
      "logits/chosen": -0.5634670257568359,
      "logits/rejected": -0.33715057373046875,
      "logps/chosen": -260.82586669921875,
      "logps/rejected": -300.147216796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7128420472145081,
      "rewards/margins": 12.095802307128906,
      "rewards/rejected": -11.382959365844727,
      "step": 980
    },
    {
      "epoch": 76.16,
      "grad_norm": 0.002795928157866001,
      "learning_rate": 3.1220930232558145e-06,
      "logits/chosen": -0.7446414232254028,
      "logits/rejected": -0.5069173574447632,
      "logps/chosen": -223.2255859375,
      "logps/rejected": -297.1784362792969,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6284193992614746,
      "rewards/margins": 12.188713073730469,
      "rewards/rejected": -11.560294151306152,
      "step": 990
    },
    {
      "epoch": 76.96,
      "grad_norm": 0.004308426287025213,
      "learning_rate": 3.102713178294574e-06,
      "logits/chosen": -0.5037425756454468,
      "logits/rejected": -0.34404563903808594,
      "logps/chosen": -250.2764129638672,
      "logps/rejected": -300.89385986328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6956365704536438,
      "rewards/margins": 12.046183586120605,
      "rewards/rejected": -11.350547790527344,
      "step": 1000
    },
    {
      "epoch": 77.72,
      "grad_norm": 0.001585041405633092,
      "learning_rate": 3.0833333333333336e-06,
      "logits/chosen": -0.5824609398841858,
      "logits/rejected": -0.4267873764038086,
      "logps/chosen": -249.8550567626953,
      "logps/rejected": -302.6629943847656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6657824516296387,
      "rewards/margins": 12.115067481994629,
      "rewards/rejected": -11.449284553527832,
      "step": 1010
    },
    {
      "epoch": 78.48,
      "grad_norm": 0.00028054381255060434,
      "learning_rate": 3.0639534883720936e-06,
      "logits/chosen": -0.8233620524406433,
      "logits/rejected": -0.5040609240531921,
      "logps/chosen": -224.8353271484375,
      "logps/rejected": -301.12017822265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6928611397743225,
      "rewards/margins": 12.667184829711914,
      "rewards/rejected": -11.974324226379395,
      "step": 1020
    },
    {
      "epoch": 79.24,
      "grad_norm": 0.0010616049403324723,
      "learning_rate": 3.044573643410853e-06,
      "logits/chosen": -0.5044550895690918,
      "logits/rejected": -0.38924017548561096,
      "logps/chosen": -244.75326538085938,
      "logps/rejected": -303.3036193847656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6376360058784485,
      "rewards/margins": 12.568632125854492,
      "rewards/rejected": -11.93099594116211,
      "step": 1030
    },
    {
      "epoch": 80.0,
      "grad_norm": 0.0003654918691609055,
      "learning_rate": 3.0251937984496127e-06,
      "logits/chosen": -0.6435185074806213,
      "logits/rejected": -0.4205775260925293,
      "logps/chosen": -248.75889587402344,
      "logps/rejected": -300.517333984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6563926339149475,
      "rewards/margins": 12.031817436218262,
      "rewards/rejected": -11.375425338745117,
      "step": 1040
    },
    {
      "epoch": 80.8,
      "grad_norm": 0.00030098954448476434,
      "learning_rate": 3.0058139534883723e-06,
      "logits/chosen": -0.5358678102493286,
      "logits/rejected": -0.37314751744270325,
      "logps/chosen": -243.1469268798828,
      "logps/rejected": -302.6021423339844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6582986116409302,
      "rewards/margins": 12.282696723937988,
      "rewards/rejected": -11.624399185180664,
      "step": 1050
    },
    {
      "epoch": 81.56,
      "grad_norm": 0.0027940834406763315,
      "learning_rate": 2.986434108527132e-06,
      "logits/chosen": -0.7877980470657349,
      "logits/rejected": -0.4648604691028595,
      "logps/chosen": -233.56126403808594,
      "logps/rejected": -302.1314392089844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6465525031089783,
      "rewards/margins": 12.289372444152832,
      "rewards/rejected": -11.64281940460205,
      "step": 1060
    },
    {
      "epoch": 82.32,
      "grad_norm": 0.0002650284441187978,
      "learning_rate": 2.967054263565892e-06,
      "logits/chosen": -0.5656123161315918,
      "logits/rejected": -0.4464755952358246,
      "logps/chosen": -255.7778778076172,
      "logps/rejected": -302.576904296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7145311236381531,
      "rewards/margins": 12.559619903564453,
      "rewards/rejected": -11.845088005065918,
      "step": 1070
    },
    {
      "epoch": 83.08,
      "grad_norm": 0.0002157731360057369,
      "learning_rate": 2.9476744186046514e-06,
      "logits/chosen": -0.44783300161361694,
      "logits/rejected": -0.3698807656764984,
      "logps/chosen": -250.39678955078125,
      "logps/rejected": -303.96490478515625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6470215320587158,
      "rewards/margins": 12.49618148803711,
      "rewards/rejected": -11.849159240722656,
      "step": 1080
    },
    {
      "epoch": 83.88,
      "grad_norm": 0.001019762479700148,
      "learning_rate": 2.928294573643411e-06,
      "logits/chosen": -0.6575813293457031,
      "logits/rejected": -0.393899142742157,
      "logps/chosen": -240.28866577148438,
      "logps/rejected": -300.50494384765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6426036357879639,
      "rewards/margins": 12.159421920776367,
      "rewards/rejected": -11.516818046569824,
      "step": 1090
    },
    {
      "epoch": 84.64,
      "grad_norm": 0.017218321561813354,
      "learning_rate": 2.9089147286821705e-06,
      "logits/chosen": -0.5219396352767944,
      "logits/rejected": -0.38178199529647827,
      "logps/chosen": -245.35806274414062,
      "logps/rejected": -302.6024475097656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6771581768989563,
      "rewards/margins": 12.150556564331055,
      "rewards/rejected": -11.47339916229248,
      "step": 1100
    },
    {
      "epoch": 85.4,
      "grad_norm": 0.0024861139245331287,
      "learning_rate": 2.88953488372093e-06,
      "logits/chosen": -0.6332459449768066,
      "logits/rejected": -0.4060579240322113,
      "logps/chosen": -261.0807189941406,
      "logps/rejected": -305.76361083984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7201261520385742,
      "rewards/margins": 12.887502670288086,
      "rewards/rejected": -12.167376518249512,
      "step": 1110
    },
    {
      "epoch": 86.16,
      "grad_norm": 0.003639533184468746,
      "learning_rate": 2.87015503875969e-06,
      "logits/chosen": -0.6164648532867432,
      "logits/rejected": -0.46870657801628113,
      "logps/chosen": -236.70924377441406,
      "logps/rejected": -301.628662109375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6366967558860779,
      "rewards/margins": 12.2562837600708,
      "rewards/rejected": -11.619585990905762,
      "step": 1120
    },
    {
      "epoch": 86.96,
      "grad_norm": 0.0020113324280828238,
      "learning_rate": 2.8507751937984497e-06,
      "logits/chosen": -0.7836140990257263,
      "logits/rejected": -0.4853498041629791,
      "logps/chosen": -226.3348846435547,
      "logps/rejected": -302.2467346191406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6626395583152771,
      "rewards/margins": 12.659791946411133,
      "rewards/rejected": -11.997152328491211,
      "step": 1130
    },
    {
      "epoch": 87.72,
      "grad_norm": 0.00024063394812401384,
      "learning_rate": 2.8313953488372097e-06,
      "logits/chosen": -0.4385364353656769,
      "logits/rejected": -0.31629982590675354,
      "logps/chosen": -262.1911315917969,
      "logps/rejected": -299.6239013671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6922671794891357,
      "rewards/margins": 11.978050231933594,
      "rewards/rejected": -11.285783767700195,
      "step": 1140
    },
    {
      "epoch": 88.48,
      "grad_norm": 0.003572976915165782,
      "learning_rate": 2.8120155038759697e-06,
      "logits/chosen": -0.767848551273346,
      "logits/rejected": -0.5683029294013977,
      "logps/chosen": -225.4828338623047,
      "logps/rejected": -306.4193115234375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6261222958564758,
      "rewards/margins": 12.898195266723633,
      "rewards/rejected": -12.272071838378906,
      "step": 1150
    },
    {
      "epoch": 89.24,
      "grad_norm": 0.000887039874214679,
      "learning_rate": 2.7926356589147292e-06,
      "logits/chosen": -0.5949277281761169,
      "logits/rejected": -0.31207582354545593,
      "logps/chosen": -257.46453857421875,
      "logps/rejected": -303.1859436035156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7402790188789368,
      "rewards/margins": 12.472811698913574,
      "rewards/rejected": -11.732532501220703,
      "step": 1160
    },
    {
      "epoch": 90.0,
      "grad_norm": 0.00024157245934475213,
      "learning_rate": 2.7732558139534888e-06,
      "logits/chosen": -0.5968464612960815,
      "logits/rejected": -0.49058952927589417,
      "logps/chosen": -235.0631103515625,
      "logps/rejected": -304.9361572265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6121309399604797,
      "rewards/margins": 12.567892074584961,
      "rewards/rejected": -11.95576000213623,
      "step": 1170
    },
    {
      "epoch": 90.8,
      "grad_norm": 0.0006125708459876478,
      "learning_rate": 2.7538759689922484e-06,
      "logits/chosen": -0.5505029559135437,
      "logits/rejected": -0.4287257790565491,
      "logps/chosen": -255.10397338867188,
      "logps/rejected": -304.0809020996094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6914885640144348,
      "rewards/margins": 12.431920051574707,
      "rewards/rejected": -11.740432739257812,
      "step": 1180
    },
    {
      "epoch": 91.56,
      "grad_norm": 0.015546695329248905,
      "learning_rate": 2.734496124031008e-06,
      "logits/chosen": -0.9115942716598511,
      "logits/rejected": -0.4684642553329468,
      "logps/chosen": -224.0972442626953,
      "logps/rejected": -303.3648376464844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6776751279830933,
      "rewards/margins": 12.90265941619873,
      "rewards/rejected": -12.224983215332031,
      "step": 1190
    },
    {
      "epoch": 92.32,
      "grad_norm": 0.00029036353225819767,
      "learning_rate": 2.715116279069768e-06,
      "logits/chosen": -0.5306596159934998,
      "logits/rejected": -0.4219565689563751,
      "logps/chosen": -244.3748016357422,
      "logps/rejected": -301.170654296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6691834330558777,
      "rewards/margins": 12.138104438781738,
      "rewards/rejected": -11.468921661376953,
      "step": 1200
    },
    {
      "epoch": 93.08,
      "grad_norm": 0.015045274049043655,
      "learning_rate": 2.6957364341085275e-06,
      "logits/chosen": -0.3685282766819,
      "logits/rejected": -0.33661404252052307,
      "logps/chosen": -265.2496337890625,
      "logps/rejected": -306.53875732421875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6548901796340942,
      "rewards/margins": 12.5806303024292,
      "rewards/rejected": -11.925740242004395,
      "step": 1210
    },
    {
      "epoch": 93.88,
      "grad_norm": 0.00017387153638992459,
      "learning_rate": 2.676356589147287e-06,
      "logits/chosen": -0.7440639138221741,
      "logits/rejected": -0.506883978843689,
      "logps/chosen": -236.20068359375,
      "logps/rejected": -308.70233154296875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6544773578643799,
      "rewards/margins": 12.841253280639648,
      "rewards/rejected": -12.186776161193848,
      "step": 1220
    },
    {
      "epoch": 94.64,
      "grad_norm": 0.002930607181042433,
      "learning_rate": 2.6569767441860466e-06,
      "logits/chosen": -0.6437901854515076,
      "logits/rejected": -0.4711727201938629,
      "logps/chosen": -229.4453125,
      "logps/rejected": -296.2555236816406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6469599008560181,
      "rewards/margins": 12.395349502563477,
      "rewards/rejected": -11.748390197753906,
      "step": 1230
    },
    {
      "epoch": 95.4,
      "grad_norm": 0.00037617312045767903,
      "learning_rate": 2.637596899224806e-06,
      "logits/chosen": -0.5652461051940918,
      "logits/rejected": -0.41068413853645325,
      "logps/chosen": -244.67259216308594,
      "logps/rejected": -311.6687316894531,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6359267234802246,
      "rewards/margins": 12.69148063659668,
      "rewards/rejected": -12.055554389953613,
      "step": 1240
    },
    {
      "epoch": 96.16,
      "grad_norm": 0.00039651637780480087,
      "learning_rate": 2.618217054263566e-06,
      "logits/chosen": -0.5921984314918518,
      "logits/rejected": -0.4670068919658661,
      "logps/chosen": -248.47630310058594,
      "logps/rejected": -303.4134521484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7167207598686218,
      "rewards/margins": 12.88933277130127,
      "rewards/rejected": -12.172612190246582,
      "step": 1250
    },
    {
      "epoch": 96.96,
      "grad_norm": 0.0033013613428920507,
      "learning_rate": 2.5988372093023257e-06,
      "logits/chosen": -0.5581535696983337,
      "logits/rejected": -0.3555300831794739,
      "logps/chosen": -250.22299194335938,
      "logps/rejected": -303.59051513671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.676338255405426,
      "rewards/margins": 12.390546798706055,
      "rewards/rejected": -11.71420955657959,
      "step": 1260
    },
    {
      "epoch": 97.72,
      "grad_norm": 0.002759435446932912,
      "learning_rate": 2.5794573643410853e-06,
      "logits/chosen": -0.6944788694381714,
      "logits/rejected": -0.43907591700553894,
      "logps/chosen": -237.26007080078125,
      "logps/rejected": -306.0767822265625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6802126169204712,
      "rewards/margins": 12.786452293395996,
      "rewards/rejected": -12.106240272521973,
      "step": 1270
    },
    {
      "epoch": 98.48,
      "grad_norm": 0.0019689069595187902,
      "learning_rate": 2.560077519379845e-06,
      "logits/chosen": -0.6856416463851929,
      "logits/rejected": -0.4261116087436676,
      "logps/chosen": -256.35089111328125,
      "logps/rejected": -301.7373352050781,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6882407665252686,
      "rewards/margins": 12.443375587463379,
      "rewards/rejected": -11.755134582519531,
      "step": 1280
    },
    {
      "epoch": 99.24,
      "grad_norm": 0.0026544244028627872,
      "learning_rate": 2.5406976744186044e-06,
      "logits/chosen": -0.3316366672515869,
      "logits/rejected": -0.3507746160030365,
      "logps/chosen": -249.0747528076172,
      "logps/rejected": -310.5168151855469,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6449392437934875,
      "rewards/margins": 12.602928161621094,
      "rewards/rejected": -11.957989692687988,
      "step": 1290
    },
    {
      "epoch": 100.0,
      "grad_norm": 5.997003972879611e-05,
      "learning_rate": 2.521317829457365e-06,
      "logits/chosen": -0.7854613661766052,
      "logits/rejected": -0.5257046222686768,
      "logps/chosen": -230.48373413085938,
      "logps/rejected": -302.46417236328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6534431576728821,
      "rewards/margins": 12.749300956726074,
      "rewards/rejected": -12.095857620239258,
      "step": 1300
    },
    {
      "epoch": 100.8,
      "grad_norm": 0.0016134403413161635,
      "learning_rate": 2.5019379844961244e-06,
      "logits/chosen": -0.5368075370788574,
      "logits/rejected": -0.3705139756202698,
      "logps/chosen": -248.864990234375,
      "logps/rejected": -304.85137939453125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6899811029434204,
      "rewards/margins": 12.51175308227539,
      "rewards/rejected": -11.821771621704102,
      "step": 1310
    },
    {
      "epoch": 101.56,
      "grad_norm": 0.0019671730697155,
      "learning_rate": 2.482558139534884e-06,
      "logits/chosen": -0.6512917876243591,
      "logits/rejected": -0.4344330430030823,
      "logps/chosen": -237.49842834472656,
      "logps/rejected": -303.92572021484375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6349695920944214,
      "rewards/margins": 12.736339569091797,
      "rewards/rejected": -12.101369857788086,
      "step": 1320
    },
    {
      "epoch": 102.32,
      "grad_norm": 0.0016613795887678862,
      "learning_rate": 2.4631782945736436e-06,
      "logits/chosen": -0.693858802318573,
      "logits/rejected": -0.5816305875778198,
      "logps/chosen": -242.19058227539062,
      "logps/rejected": -309.740478515625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6840848922729492,
      "rewards/margins": 12.813984870910645,
      "rewards/rejected": -12.129899978637695,
      "step": 1330
    },
    {
      "epoch": 103.08,
      "grad_norm": 0.0002497908135410398,
      "learning_rate": 2.4437984496124035e-06,
      "logits/chosen": -0.5867346525192261,
      "logits/rejected": -0.3971612751483917,
      "logps/chosen": -241.4615478515625,
      "logps/rejected": -303.4579162597656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6664378643035889,
      "rewards/margins": 12.82558822631836,
      "rewards/rejected": -12.159150123596191,
      "step": 1340
    },
    {
      "epoch": 103.88,
      "grad_norm": 0.001251683570444584,
      "learning_rate": 2.424418604651163e-06,
      "logits/chosen": -0.44853073358535767,
      "logits/rejected": -0.37055206298828125,
      "logps/chosen": -261.6973571777344,
      "logps/rejected": -306.63348388671875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6874219179153442,
      "rewards/margins": 12.559484481811523,
      "rewards/rejected": -11.872062683105469,
      "step": 1350
    },
    {
      "epoch": 104.64,
      "grad_norm": 0.0012548157246783376,
      "learning_rate": 2.4050387596899227e-06,
      "logits/chosen": -0.7892155051231384,
      "logits/rejected": -0.4404791295528412,
      "logps/chosen": -242.158203125,
      "logps/rejected": -305.15325927734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6979121565818787,
      "rewards/margins": 12.722129821777344,
      "rewards/rejected": -12.02421760559082,
      "step": 1360
    },
    {
      "epoch": 105.4,
      "grad_norm": 0.00021265438408590853,
      "learning_rate": 2.3856589147286822e-06,
      "logits/chosen": -0.628945529460907,
      "logits/rejected": -0.5214906334877014,
      "logps/chosen": -228.8519287109375,
      "logps/rejected": -311.61328125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5675442218780518,
      "rewards/margins": 13.170358657836914,
      "rewards/rejected": -12.602815628051758,
      "step": 1370
    },
    {
      "epoch": 106.16,
      "grad_norm": 0.00024869924527592957,
      "learning_rate": 2.3662790697674422e-06,
      "logits/chosen": -0.47680243849754333,
      "logits/rejected": -0.36278876662254333,
      "logps/chosen": -254.0277557373047,
      "logps/rejected": -303.7907409667969,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7343315482139587,
      "rewards/margins": 12.607866287231445,
      "rewards/rejected": -11.873536109924316,
      "step": 1380
    },
    {
      "epoch": 106.96,
      "grad_norm": 0.0032163357827812433,
      "learning_rate": 2.346899224806202e-06,
      "logits/chosen": -0.7594529390335083,
      "logits/rejected": -0.5034220814704895,
      "logps/chosen": -232.825439453125,
      "logps/rejected": -302.10504150390625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6650729179382324,
      "rewards/margins": 12.612245559692383,
      "rewards/rejected": -11.947171211242676,
      "step": 1390
    },
    {
      "epoch": 107.72,
      "grad_norm": 0.00027751803281717,
      "learning_rate": 2.3275193798449614e-06,
      "logits/chosen": -0.5437166690826416,
      "logits/rejected": -0.38662827014923096,
      "logps/chosen": -246.65084838867188,
      "logps/rejected": -310.5318603515625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6439225077629089,
      "rewards/margins": 13.07494068145752,
      "rewards/rejected": -12.431018829345703,
      "step": 1400
    },
    {
      "epoch": 108.48,
      "grad_norm": 0.000425709062255919,
      "learning_rate": 2.308139534883721e-06,
      "logits/chosen": -0.9194316864013672,
      "logits/rejected": -0.5995473265647888,
      "logps/chosen": -217.58819580078125,
      "logps/rejected": -302.9895935058594,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6545838117599487,
      "rewards/margins": 12.77912425994873,
      "rewards/rejected": -12.124540328979492,
      "step": 1410
    },
    {
      "epoch": 109.24,
      "grad_norm": 0.0003722833935171366,
      "learning_rate": 2.288759689922481e-06,
      "logits/chosen": -0.21216513216495514,
      "logits/rejected": -0.23960080742835999,
      "logps/chosen": -284.8988342285156,
      "logps/rejected": -306.5694885253906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7282631993293762,
      "rewards/margins": 12.309877395629883,
      "rewards/rejected": -11.581612586975098,
      "step": 1420
    },
    {
      "epoch": 110.0,
      "grad_norm": 0.0027829071041196585,
      "learning_rate": 2.2693798449612405e-06,
      "logits/chosen": -0.7278523445129395,
      "logits/rejected": -0.5157821178436279,
      "logps/chosen": -232.1168212890625,
      "logps/rejected": -306.5225524902344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6433205008506775,
      "rewards/margins": 12.94277286529541,
      "rewards/rejected": -12.299452781677246,
      "step": 1430
    },
    {
      "epoch": 110.8,
      "grad_norm": 0.0031113470904529095,
      "learning_rate": 2.25e-06,
      "logits/chosen": -0.6442486047744751,
      "logits/rejected": -0.46079668402671814,
      "logps/chosen": -242.35580444335938,
      "logps/rejected": -309.3992614746094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6443485021591187,
      "rewards/margins": 12.804341316223145,
      "rewards/rejected": -12.159993171691895,
      "step": 1440
    },
    {
      "epoch": 111.56,
      "grad_norm": 0.00012815665104426444,
      "learning_rate": 2.23062015503876e-06,
      "logits/chosen": -0.4131605625152588,
      "logits/rejected": -0.29357656836509705,
      "logps/chosen": -265.67333984375,
      "logps/rejected": -302.21905517578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7574808597564697,
      "rewards/margins": 12.631237030029297,
      "rewards/rejected": -11.87375545501709,
      "step": 1450
    },
    {
      "epoch": 112.32,
      "grad_norm": 0.00020771149138454348,
      "learning_rate": 2.2112403100775196e-06,
      "logits/chosen": -0.8735194206237793,
      "logits/rejected": -0.5478941202163696,
      "logps/chosen": -216.4208526611328,
      "logps/rejected": -307.6007080078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5796425342559814,
      "rewards/margins": 12.858222961425781,
      "rewards/rejected": -12.278580665588379,
      "step": 1460
    },
    {
      "epoch": 113.08,
      "grad_norm": 0.00047654611989855766,
      "learning_rate": 2.191860465116279e-06,
      "logits/chosen": -0.6208297610282898,
      "logits/rejected": -0.49661165475845337,
      "logps/chosen": -242.42604064941406,
      "logps/rejected": -308.0562438964844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6753324866294861,
      "rewards/margins": 13.008697509765625,
      "rewards/rejected": -12.333365440368652,
      "step": 1470
    },
    {
      "epoch": 113.88,
      "grad_norm": 0.0010050316341221333,
      "learning_rate": 2.1724806201550387e-06,
      "logits/chosen": -0.5941806435585022,
      "logits/rejected": -0.42557111382484436,
      "logps/chosen": -251.3690948486328,
      "logps/rejected": -306.3380432128906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.669643759727478,
      "rewards/margins": 12.834495544433594,
      "rewards/rejected": -12.164851188659668,
      "step": 1480
    },
    {
      "epoch": 114.64,
      "grad_norm": 0.0004492809239309281,
      "learning_rate": 2.1531007751937983e-06,
      "logits/chosen": -0.3589112460613251,
      "logits/rejected": -0.3312912583351135,
      "logps/chosen": -259.0372314453125,
      "logps/rejected": -304.554443359375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6960588693618774,
      "rewards/margins": 12.738677978515625,
      "rewards/rejected": -12.042620658874512,
      "step": 1490
    },
    {
      "epoch": 115.4,
      "grad_norm": 0.0002946901659015566,
      "learning_rate": 2.1337209302325583e-06,
      "logits/chosen": -0.5482641458511353,
      "logits/rejected": -0.46254393458366394,
      "logps/chosen": -251.32354736328125,
      "logps/rejected": -314.845703125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6617890000343323,
      "rewards/margins": 12.9368314743042,
      "rewards/rejected": -12.275042533874512,
      "step": 1500
    },
    {
      "epoch": 116.16,
      "grad_norm": 0.0007497564074583352,
      "learning_rate": 2.1143410852713183e-06,
      "logits/chosen": -0.7286378145217896,
      "logits/rejected": -0.4510856568813324,
      "logps/chosen": -239.12579345703125,
      "logps/rejected": -301.2706604003906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7068586945533752,
      "rewards/margins": 12.650489807128906,
      "rewards/rejected": -11.943631172180176,
      "step": 1510
    },
    {
      "epoch": 116.96,
      "grad_norm": 0.0004372547846287489,
      "learning_rate": 2.094961240310078e-06,
      "logits/chosen": -0.7889747619628906,
      "logits/rejected": -0.571434736251831,
      "logps/chosen": -227.02359008789062,
      "logps/rejected": -306.7922668457031,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6357630491256714,
      "rewards/margins": 13.079652786254883,
      "rewards/rejected": -12.443888664245605,
      "step": 1520
    },
    {
      "epoch": 117.72,
      "grad_norm": 0.0011429423466324806,
      "learning_rate": 2.0755813953488374e-06,
      "logits/chosen": -0.7289916276931763,
      "logits/rejected": -0.5245400071144104,
      "logps/chosen": -228.2292022705078,
      "logps/rejected": -307.7292175292969,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6317850351333618,
      "rewards/margins": 13.148356437683105,
      "rewards/rejected": -12.516571044921875,
      "step": 1530
    },
    {
      "epoch": 118.48,
      "grad_norm": 0.0002991428191307932,
      "learning_rate": 2.056201550387597e-06,
      "logits/chosen": -0.24208977818489075,
      "logits/rejected": -0.22638562321662903,
      "logps/chosen": -275.8890686035156,
      "logps/rejected": -303.2260437011719,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7189075350761414,
      "rewards/margins": 12.213308334350586,
      "rewards/rejected": -11.494401931762695,
      "step": 1540
    },
    {
      "epoch": 119.24,
      "grad_norm": 0.00022672275372315198,
      "learning_rate": 2.0368217054263566e-06,
      "logits/chosen": -0.8691487312316895,
      "logits/rejected": -0.5847871899604797,
      "logps/chosen": -236.18310546875,
      "logps/rejected": -310.1603698730469,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6949344277381897,
      "rewards/margins": 13.141939163208008,
      "rewards/rejected": -12.447003364562988,
      "step": 1550
    },
    {
      "epoch": 120.0,
      "grad_norm": 0.00016397066065110266,
      "learning_rate": 2.0174418604651166e-06,
      "logits/chosen": -0.5541513562202454,
      "logits/rejected": -0.43183568120002747,
      "logps/chosen": -236.9140625,
      "logps/rejected": -310.51678466796875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6353634595870972,
      "rewards/margins": 13.100374221801758,
      "rewards/rejected": -12.465009689331055,
      "step": 1560
    },
    {
      "epoch": 120.8,
      "grad_norm": 0.0001494531607022509,
      "learning_rate": 1.998062015503876e-06,
      "logits/chosen": -0.3882666528224945,
      "logits/rejected": -0.29978594183921814,
      "logps/chosen": -255.61019897460938,
      "logps/rejected": -308.3680114746094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6684735417366028,
      "rewards/margins": 12.684837341308594,
      "rewards/rejected": -12.016363143920898,
      "step": 1570
    },
    {
      "epoch": 121.56,
      "grad_norm": 0.000398260512156412,
      "learning_rate": 1.978682170542636e-06,
      "logits/chosen": -0.7387807965278625,
      "logits/rejected": -0.5482575297355652,
      "logps/chosen": -237.74827575683594,
      "logps/rejected": -311.29052734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6286616921424866,
      "rewards/margins": 13.197054862976074,
      "rewards/rejected": -12.568394660949707,
      "step": 1580
    },
    {
      "epoch": 122.32,
      "grad_norm": 0.011141776107251644,
      "learning_rate": 1.9593023255813957e-06,
      "logits/chosen": -0.7214860320091248,
      "logits/rejected": -0.5328518748283386,
      "logps/chosen": -237.32858276367188,
      "logps/rejected": -305.0401916503906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7214888334274292,
      "rewards/margins": 12.8821439743042,
      "rewards/rejected": -12.160655975341797,
      "step": 1590
    },
    {
      "epoch": 123.08,
      "grad_norm": 0.00042961910367012024,
      "learning_rate": 1.9399224806201552e-06,
      "logits/chosen": -0.6117517352104187,
      "logits/rejected": -0.4427599608898163,
      "logps/chosen": -242.40365600585938,
      "logps/rejected": -307.42608642578125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.658612072467804,
      "rewards/margins": 12.991021156311035,
      "rewards/rejected": -12.332409858703613,
      "step": 1600
    },
    {
      "epoch": 123.88,
      "grad_norm": 0.00023546154261566699,
      "learning_rate": 1.920542635658915e-06,
      "logits/chosen": -0.5507596135139465,
      "logits/rejected": -0.43865060806274414,
      "logps/chosen": -254.3568572998047,
      "logps/rejected": -310.6494445800781,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6619391441345215,
      "rewards/margins": 12.940774917602539,
      "rewards/rejected": -12.278836250305176,
      "step": 1610
    },
    {
      "epoch": 124.64,
      "grad_norm": 0.0004732697852887213,
      "learning_rate": 1.9011627906976746e-06,
      "logits/chosen": -0.4655369818210602,
      "logits/rejected": -0.38330724835395813,
      "logps/chosen": -251.3765411376953,
      "logps/rejected": -305.4798583984375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.68461012840271,
      "rewards/margins": 12.92059326171875,
      "rewards/rejected": -12.235983848571777,
      "step": 1620
    },
    {
      "epoch": 125.4,
      "grad_norm": 0.00045389329898171127,
      "learning_rate": 1.8817829457364342e-06,
      "logits/chosen": -0.8446912169456482,
      "logits/rejected": -0.5147659182548523,
      "logps/chosen": -221.81874084472656,
      "logps/rejected": -305.7295227050781,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6614355444908142,
      "rewards/margins": 12.843738555908203,
      "rewards/rejected": -12.182302474975586,
      "step": 1630
    },
    {
      "epoch": 126.16,
      "grad_norm": 0.0007010081899352372,
      "learning_rate": 1.862403100775194e-06,
      "logits/chosen": -0.6838492155075073,
      "logits/rejected": -0.537689745426178,
      "logps/chosen": -237.7386932373047,
      "logps/rejected": -307.7431335449219,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.653649091720581,
      "rewards/margins": 13.044464111328125,
      "rewards/rejected": -12.390815734863281,
      "step": 1640
    },
    {
      "epoch": 126.96,
      "grad_norm": 0.0004746716294903308,
      "learning_rate": 1.8430232558139535e-06,
      "logits/chosen": -0.586328387260437,
      "logits/rejected": -0.41777902841567993,
      "logps/chosen": -252.2989044189453,
      "logps/rejected": -308.4156494140625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6835668087005615,
      "rewards/margins": 12.98982048034668,
      "rewards/rejected": -12.306253433227539,
      "step": 1650
    },
    {
      "epoch": 127.72,
      "grad_norm": 0.00045745400711894035,
      "learning_rate": 1.8236434108527135e-06,
      "logits/chosen": -0.8777976036071777,
      "logits/rejected": -0.5550107359886169,
      "logps/chosen": -228.7904052734375,
      "logps/rejected": -306.2751770019531,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6857044100761414,
      "rewards/margins": 13.086935043334961,
      "rewards/rejected": -12.401230812072754,
      "step": 1660
    },
    {
      "epoch": 128.48,
      "grad_norm": 0.00076991569949314,
      "learning_rate": 1.804263565891473e-06,
      "logits/chosen": -0.274643212556839,
      "logits/rejected": -0.277915894985199,
      "logps/chosen": -265.31817626953125,
      "logps/rejected": -306.603515625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.68077152967453,
      "rewards/margins": 12.614725112915039,
      "rewards/rejected": -11.933953285217285,
      "step": 1670
    },
    {
      "epoch": 129.24,
      "grad_norm": 0.00040985600207932293,
      "learning_rate": 1.7848837209302328e-06,
      "logits/chosen": -0.5155746936798096,
      "logits/rejected": -0.4522785246372223,
      "logps/chosen": -258.26043701171875,
      "logps/rejected": -316.4244384765625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6578455567359924,
      "rewards/margins": 13.394807815551758,
      "rewards/rejected": -12.736963272094727,
      "step": 1680
    },
    {
      "epoch": 130.0,
      "grad_norm": 0.00011010064918082207,
      "learning_rate": 1.7655038759689924e-06,
      "logits/chosen": -0.7358257174491882,
      "logits/rejected": -0.5105008482933044,
      "logps/chosen": -226.7077178955078,
      "logps/rejected": -306.2177734375,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6606104969978333,
      "rewards/margins": 12.885235786437988,
      "rewards/rejected": -12.224626541137695,
      "step": 1690
    },
    {
      "epoch": 130.8,
      "grad_norm": 0.00071405537892133,
      "learning_rate": 1.746124031007752e-06,
      "logits/chosen": -0.5152201652526855,
      "logits/rejected": -0.4075295329093933,
      "logps/chosen": -253.88134765625,
      "logps/rejected": -308.1256408691406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7019898295402527,
      "rewards/margins": 13.003122329711914,
      "rewards/rejected": -12.301132202148438,
      "step": 1700
    },
    {
      "epoch": 131.56,
      "grad_norm": 0.00013635845971293747,
      "learning_rate": 1.7267441860465118e-06,
      "logits/chosen": -0.6061543226242065,
      "logits/rejected": -0.45218974351882935,
      "logps/chosen": -238.685546875,
      "logps/rejected": -309.0203552246094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5987685322761536,
      "rewards/margins": 12.819602012634277,
      "rewards/rejected": -12.220832824707031,
      "step": 1710
    },
    {
      "epoch": 132.32,
      "grad_norm": 0.0004291584191378206,
      "learning_rate": 1.7073643410852713e-06,
      "logits/chosen": -0.6848984360694885,
      "logits/rejected": -0.509705662727356,
      "logps/chosen": -242.27745056152344,
      "logps/rejected": -306.5531921386719,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7570951581001282,
      "rewards/margins": 12.934106826782227,
      "rewards/rejected": -12.177011489868164,
      "step": 1720
    },
    {
      "epoch": 133.08,
      "grad_norm": 0.0002874369965866208,
      "learning_rate": 1.687984496124031e-06,
      "logits/chosen": -0.7004019618034363,
      "logits/rejected": -0.5235232710838318,
      "logps/chosen": -238.7022247314453,
      "logps/rejected": -312.9796447753906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.605758011341095,
      "rewards/margins": 13.47036361694336,
      "rewards/rejected": -12.864605903625488,
      "step": 1730
    },
    {
      "epoch": 133.88,
      "grad_norm": 0.0014952358324080706,
      "learning_rate": 1.6686046511627909e-06,
      "logits/chosen": -0.48651403188705444,
      "logits/rejected": -0.31651780009269714,
      "logps/chosen": -254.8404998779297,
      "logps/rejected": -308.4689025878906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6810201406478882,
      "rewards/margins": 12.845690727233887,
      "rewards/rejected": -12.164670944213867,
      "step": 1740
    },
    {
      "epoch": 134.64,
      "grad_norm": 0.010288766585290432,
      "learning_rate": 1.6492248062015507e-06,
      "logits/chosen": -0.6776224374771118,
      "logits/rejected": -0.5562111735343933,
      "logps/chosen": -222.3286895751953,
      "logps/rejected": -306.897705078125,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6562877297401428,
      "rewards/margins": 12.9512357711792,
      "rewards/rejected": -12.294949531555176,
      "step": 1750
    },
    {
      "epoch": 135.4,
      "grad_norm": 0.00011530044139362872,
      "learning_rate": 1.6298449612403102e-06,
      "logits/chosen": -0.6139708161354065,
      "logits/rejected": -0.44300577044487,
      "logps/chosen": -255.9483184814453,
      "logps/rejected": -309.5279541015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6813667416572571,
      "rewards/margins": 13.129450798034668,
      "rewards/rejected": -12.448083877563477,
      "step": 1760
    },
    {
      "epoch": 136.16,
      "grad_norm": 0.0003140304470434785,
      "learning_rate": 1.61046511627907e-06,
      "logits/chosen": -0.6182144284248352,
      "logits/rejected": -0.4884955883026123,
      "logps/chosen": -240.3421630859375,
      "logps/rejected": -308.2602233886719,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6431348919868469,
      "rewards/margins": 12.978507041931152,
      "rewards/rejected": -12.335371971130371,
      "step": 1770
    },
    {
      "epoch": 136.96,
      "grad_norm": 0.001742054708302021,
      "learning_rate": 1.5910852713178296e-06,
      "logits/chosen": -0.6824049353599548,
      "logits/rejected": -0.45698994398117065,
      "logps/chosen": -243.15414428710938,
      "logps/rejected": -309.9869689941406,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7016316056251526,
      "rewards/margins": 13.224973678588867,
      "rewards/rejected": -12.523343086242676,
      "step": 1780
    },
    {
      "epoch": 137.72,
      "grad_norm": 0.001734700403176248,
      "learning_rate": 1.5717054263565891e-06,
      "logits/chosen": -0.6648292541503906,
      "logits/rejected": -0.49609124660491943,
      "logps/chosen": -239.4416961669922,
      "logps/rejected": -310.7166442871094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6462496519088745,
      "rewards/margins": 13.236300468444824,
      "rewards/rejected": -12.590049743652344,
      "step": 1790
    },
    {
      "epoch": 138.48,
      "grad_norm": 0.00040741346310824156,
      "learning_rate": 1.552325581395349e-06,
      "logits/chosen": -0.3377314805984497,
      "logits/rejected": -0.2751561105251312,
      "logps/chosen": -263.8218688964844,
      "logps/rejected": -305.2076110839844,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7003769874572754,
      "rewards/margins": 12.407352447509766,
      "rewards/rejected": -11.706976890563965,
      "step": 1800
    },
    {
      "epoch": 139.24,
      "grad_norm": 0.00044290663208812475,
      "learning_rate": 1.5329457364341085e-06,
      "logits/chosen": -0.9218258857727051,
      "logits/rejected": -0.6140400171279907,
      "logps/chosen": -218.65650939941406,
      "logps/rejected": -307.92742919921875,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6397715210914612,
      "rewards/margins": 13.408341407775879,
      "rewards/rejected": -12.768569946289062,
      "step": 1810
    },
    {
      "epoch": 140.0,
      "grad_norm": 0.0032125760335475206,
      "learning_rate": 1.5135658914728685e-06,
      "logits/chosen": -0.4821813106536865,
      "logits/rejected": -0.4494117498397827,
      "logps/chosen": -258.16680908203125,
      "logps/rejected": -313.5083312988281,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.695873498916626,
      "rewards/margins": 13.195893287658691,
      "rewards/rejected": -12.500020027160645,
      "step": 1820
    },
    {
      "epoch": 140.8,
      "grad_norm": 0.0001767954381648451,
      "learning_rate": 1.494186046511628e-06,
      "logits/chosen": -0.7232311964035034,
      "logits/rejected": -0.46741360425949097,
      "logps/chosen": -242.07510375976562,
      "logps/rejected": -310.1014099121094,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6570209860801697,
      "rewards/margins": 13.064623832702637,
      "rewards/rejected": -12.407602310180664,
      "step": 1830
    },
    {
      "epoch": 141.56,
      "grad_norm": 0.00031355360988527536,
      "learning_rate": 1.4748062015503878e-06,
      "logits/chosen": -0.32272040843963623,
      "logits/rejected": -0.35933151841163635,
      "logps/chosen": -263.7533264160156,
      "logps/rejected": -313.4415588378906,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7040899395942688,
      "rewards/margins": 13.128617286682129,
      "rewards/rejected": -12.424527168273926,
      "step": 1840
    },
    {
      "epoch": 142.32,
      "grad_norm": 0.002893583383411169,
      "learning_rate": 1.4554263565891474e-06,
      "logits/chosen": -0.9088014364242554,
      "logits/rejected": -0.6005719304084778,
      "logps/chosen": -214.1971893310547,
      "logps/rejected": -300.9120178222656,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6058688163757324,
      "rewards/margins": 12.852197647094727,
      "rewards/rejected": -12.246329307556152,
      "step": 1850
    },
    {
      "epoch": 143.08,
      "grad_norm": 0.0002306661626789719,
      "learning_rate": 1.4360465116279072e-06,
      "logits/chosen": -0.5807471871376038,
      "logits/rejected": -0.4450721740722656,
      "logps/chosen": -247.5732421875,
      "logps/rejected": -312.74420166015625,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7134566307067871,
      "rewards/margins": 13.360855102539062,
      "rewards/rejected": -12.647397994995117,
      "step": 1860
    },
    {
      "epoch": 143.88,
      "grad_norm": 0.00015965703641995788,
      "learning_rate": 1.4166666666666667e-06,
      "logits/chosen": -0.42489394545555115,
      "logits/rejected": -0.370220810174942,
      "logps/chosen": -259.99359130859375,
      "logps/rejected": -308.8339538574219,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6704871654510498,
      "rewards/margins": 12.853063583374023,
      "rewards/rejected": -12.182578086853027,
      "step": 1870
    },
    {
      "epoch": 144.64,
      "grad_norm": 0.0005643338663503528,
      "learning_rate": 1.3972868217054265e-06,
      "logits/chosen": -0.37209898233413696,
      "logits/rejected": -0.3864094913005829,
      "logps/chosen": -254.92665100097656,
      "logps/rejected": -312.9834899902344,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6609394550323486,
      "rewards/margins": 13.254260063171387,
      "rewards/rejected": -12.5933198928833,
      "step": 1880
    },
    {
      "epoch": 145.4,
      "grad_norm": 0.0016422605840489268,
      "learning_rate": 1.377906976744186e-06,
      "logits/chosen": -0.983681857585907,
      "logits/rejected": -0.6415705680847168,
      "logps/chosen": -232.14707946777344,
      "logps/rejected": -305.8015441894531,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6933891177177429,
      "rewards/margins": 13.036385536193848,
      "rewards/rejected": -12.342996597290039,
      "step": 1890
    },
    {
      "epoch": 146.16,
      "grad_norm": 0.0009791491320356727,
      "learning_rate": 1.358527131782946e-06,
      "logits/chosen": -0.5887585282325745,
      "logits/rejected": -0.42005568742752075,
      "logps/chosen": -236.9714813232422,
      "logps/rejected": -315.9906311035156,
      "loss": 0.0,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.624896764755249,
      "rewards/margins": 13.29792308807373,
      "rewards/rejected": -12.673027038574219,
      "step": 1900
    }
  ],
  "logging_steps": 10,
  "max_steps": 2600,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 200,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
