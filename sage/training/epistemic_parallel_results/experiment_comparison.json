{
  "experiment": "parallel_epistemic_training",
  "date": "2025-10-31T21:50:39.188908",
  "platform": "Jetson AGX Thor",
  "dataset_size": 115,
  "models": {
    "qwen": {
      "model_key": "qwen",
      "model_name": "Qwen/Qwen2.5-0.5B",
      "parameters": "494M",
      "expected_inertia": "low",
      "training_time_seconds": 79.059751,
      "dataset_size": 115,
      "epochs": 5,
      "final_loss": null,
      "learning_curve": [
        {
          "step": 5,
          "loss": 0.6918
        },
        {
          "step": 10,
          "loss": 0.6678
        },
        {
          "step": 15,
          "loss": 0.5946
        },
        {
          "step": 20,
          "loss": 0.4899
        },
        {
          "step": 25,
          "loss": 0.3668
        },
        {
          "step": 30,
          "loss": 0.2581
        },
        {
          "step": 35,
          "loss": 0.1213
        },
        {
          "step": 40,
          "loss": 0.0476
        },
        {
          "step": 45,
          "loss": 0.0121
        },
        {
          "step": 50,
          "loss": 0.0015
        },
        {
          "step": 55,
          "loss": 0.0005
        },
        {
          "step": 60,
          "loss": 0.0001
        },
        {
          "step": 65,
          "loss": 0.0001
        },
        {
          "step": 70,
          "loss": 0.0
        },
        {
          "step": 75,
          "loss": 0.0
        }
      ]
    },
    "phi2": {
      "model_key": "phi2",
      "model_name": "microsoft/phi-2",
      "parameters": "2.7B",
      "expected_inertia": "high",
      "training_time_seconds": 213.833997,
      "dataset_size": 115,
      "epochs": 5,
      "final_loss": null,
      "learning_curve": [
        {
          "step": 5,
          "loss": 0.6926
        },
        {
          "step": 10,
          "loss": 0.686
        },
        {
          "step": 15,
          "loss": 0.6645
        },
        {
          "step": 20,
          "loss": 0.6149
        },
        {
          "step": 25,
          "loss": 0.5469
        },
        {
          "step": 30,
          "loss": 0.4698
        },
        {
          "step": 35,
          "loss": 0.3402
        },
        {
          "step": 40,
          "loss": 0.221
        },
        {
          "step": 45,
          "loss": 0.1108
        },
        {
          "step": 50,
          "loss": 0.0394
        },
        {
          "step": 55,
          "loss": 0.0131
        },
        {
          "step": 60,
          "loss": 0.0064
        },
        {
          "step": 65,
          "loss": 0.0033
        },
        {
          "step": 70,
          "loss": 0.0038
        },
        {
          "step": 75,
          "loss": 0.0025
        }
      ]
    }
  },
  "hypothesis": "Larger models (Phi-2 2.7B) will show higher size inertia than smaller models (Qwen 0.5B)",
  "observations": {
    "qwen_time": 79.059751,
    "phi2_time": 213.833997,
    "time_ratio": 2.704713767691983,
    "qwen_final_loss": null,
    "phi2_final_loss": null
  }
}