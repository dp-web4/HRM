#!/usr/bin/env python3
"""
Sparse MoE Expert Selection Masking - Unit Tests

Tests Thor's Session 52 fix for per-layer expert availability masking.

Key insight: Qwen3-Omni uses sparse MoE with varying expert counts per layer.
- Layer 0: 128 experts
- Layer 1: 76 experts
- Layer 9: 79 experts
- etc.

Total: 5,612 experts across 48 layers (not uniform 6,144)

This test validates the masking logic without needing actual model weights.
"""

import torch
import torch.nn.functional as F
import time

def test_sparse_masking_logic():
    """Test that masking correctly filters unavailable experts"""
    print("\n" + "="*60)
    print("TEST 1: Sparse Masking Logic")
    print("="*60)

    # Simulate router logits for 128 potential experts
    torch.manual_seed(42)
    router_logits = torch.randn(128)

    # Define sparse layer: only experts [0, 2, 5, 10, 15, 20, 50, 100] available
    available_experts = [0, 2, 5, 10, 15, 20, 50, 100]

    print(f"\nRouter logits shape: {router_logits.shape}")
    print(f"Available experts: {available_experts}")
    print(f"Unavailable count: {128 - len(available_experts)}")

    # Apply Thor's masking approach
    mask = torch.full_like(router_logits, float('-inf'))
    mask[available_experts] = 0
    masked_logits = router_logits + mask

    # Select top-4 experts
    top_k_values, top_k_indices = torch.topk(masked_logits, k=4)

    print(f"\nSelected experts (top-4): {top_k_indices.tolist()}")
    print(f"Selection scores: {top_k_values.tolist()}")

    # Validate: all selected experts must be in available list
    selected = top_k_indices.tolist()
    for expert_id in selected:
        assert expert_id in available_experts, f"ERROR: Selected unavailable expert {expert_id}!"

    print("\nâœ… PASS: All selected experts are available")
    return True


def test_empty_mask_default():
    """Test that missing availability map defaults to full 128 experts"""
    print("\n" + "="*60)
    print("TEST 2: Default Behavior (No Availability Map)")
    print("="*60)

    # Simulate default: all 128 available
    expert_availability = {i: list(range(128)) for i in range(48)}

    torch.manual_seed(123)
    router_logits = torch.randn(128)

    layer_id = 25
    available_experts = expert_availability.get(layer_id, list(range(128)))

    print(f"\nLayer {layer_id}: {len(available_experts)} experts available")

    # Apply mask (should be all zeros for full availability)
    mask = torch.full_like(router_logits, float('-inf'))
    mask[available_experts] = 0

    # Verify mask doesn't block anything
    valid_positions = (mask == 0).sum().item()
    print(f"Valid positions in mask: {valid_positions}")

    assert valid_positions == 128, f"Expected 128, got {valid_positions}"

    # Top-4 should be pure top-4 from router
    masked_logits = router_logits + mask
    top_k_values, top_k_indices = torch.topk(masked_logits, k=4)

    # Compare with unmasked
    unmasked_top_k_values, unmasked_top_k_indices = torch.topk(router_logits, k=4)

    assert torch.equal(top_k_indices, unmasked_top_k_indices), "Masked != unmasked for full availability"

    print(f"Top-4 experts: {top_k_indices.tolist()}")
    print("\nâœ… PASS: Default behavior preserves all experts")
    return True


def test_sparse_layer_simulation():
    """Simulate actual Qwen3-Omni sparse architecture"""
    print("\n" + "="*60)
    print("TEST 3: Qwen3-Omni Sparse Architecture Simulation")
    print("="*60)

    # Simulate real sparse architecture based on Thor's discovery
    # Total: 5,612 experts across 48 layers (not uniform 6,144)
    expert_availability = {
        0: list(range(128)),  # Layer 0: full 128
        1: list(range(76)),   # Layer 1: sparse 76
        9: list(range(79)),   # Layer 9: sparse 79
        25: list(range(110)), # Layer 25: sparse 110
        47: list(range(95)),  # Layer 47: sparse 95
    }

    torch.manual_seed(456)

    results = []
    for layer_id in [0, 1, 9, 25, 47]:
        router_logits = torch.randn(128)
        available = expert_availability.get(layer_id, list(range(128)))

        # Apply mask
        mask = torch.full_like(router_logits, float('-inf'))
        mask[available] = 0
        masked_logits = router_logits + mask

        # Select top-4
        top_k_values, top_k_indices = torch.topk(masked_logits, k=4)
        selected = top_k_indices.tolist()

        # Validate
        for exp_id in selected:
            assert exp_id in available, f"Layer {layer_id}: Selected unavailable expert {exp_id}"

        results.append({
            'layer': layer_id,
            'available': len(available),
            'selected': selected,
            'max_valid': max(available)
        })

        print(f"\nLayer {layer_id}: {len(available)} experts available")
        print(f"  Selected: {selected}")
        print(f"  Max valid expert_id: {max(available)}")

    print("\nâœ… PASS: All layers correctly mask to available experts")
    return True


def test_snarc_path_masking():
    """Test that SNARC-augmented path also respects masking"""
    print("\n" + "="*60)
    print("TEST 4: SNARC Path Masking")
    print("="*60)

    # Simulate SNARC scores
    torch.manual_seed(789)
    snarc_scores = torch.randn(128)

    # Sparse layer
    available_experts = [0, 5, 10, 15, 20, 25, 30, 35, 40, 45]

    print(f"\nSNARC scores shape: {snarc_scores.shape}")
    print(f"Available experts: {available_experts}")

    # Apply same mask as router path (Thor's fix)
    mask = torch.full_like(snarc_scores, float('-inf'))
    mask[available_experts] = 0
    masked_snarc = snarc_scores + mask

    # Select top-4
    top_k_values, top_k_indices = torch.topk(masked_snarc, k=4)
    selected = top_k_indices.tolist()

    print(f"Selected experts (SNARC path): {selected}")

    # Validate
    for exp_id in selected:
        assert exp_id in available_experts, f"SNARC path selected unavailable expert {exp_id}"

    print("\nâœ… PASS: SNARC path correctly masks to available experts")
    return True


def test_edge_performance():
    """Test masking performance on edge hardware"""
    print("\n" + "="*60)
    print("TEST 5: Edge Performance")
    print("="*60)

    # Measure masking overhead
    torch.manual_seed(999)
    router_logits = torch.randn(128)
    available_experts = list(range(76))  # Sparse layer

    # Warmup
    for _ in range(10):
        mask = torch.full_like(router_logits, float('-inf'))
        mask[available_experts] = 0
        masked = router_logits + mask
        _, _ = torch.topk(masked, k=4)

    # Benchmark
    iterations = 1000
    start = time.perf_counter()
    for _ in range(iterations):
        mask = torch.full_like(router_logits, float('-inf'))
        mask[available_experts] = 0
        masked = router_logits + mask
        _, _ = torch.topk(masked, k=4)
    elapsed = time.perf_counter() - start

    avg_us = (elapsed / iterations) * 1_000_000

    print(f"\nMasking + top-k selection:")
    print(f"  Iterations: {iterations}")
    print(f"  Total time: {elapsed*1000:.2f}ms")
    print(f"  Average per call: {avg_us:.2f}Âµs")

    # Context: 12-layer model routing overhead analysis
    layers = 12
    routing_overhead_ms = (avg_us * layers) / 1000
    typical_inference_ms = 240  # Conservative estimate for edge
    overhead_pct = routing_overhead_ms / typical_inference_ms * 100

    print(f"\n  Context (12-layer model):")
    print(f"    Total routing overhead: {routing_overhead_ms:.2f}ms")
    print(f"    Typical inference: ~{typical_inference_ms}ms")
    print(f"    Overhead percentage: {overhead_pct:.2f}%")

    # Edge target: < 1% overhead of total inference (more realistic)
    assert overhead_pct < 2.0, f"Routing overhead too high: {overhead_pct:.2f}% (target: <2%)"

    print(f"\nâœ… PASS: {overhead_pct:.2f}% routing overhead (target: <2%)")
    return True


def run_all_tests():
    """Run all sparse MoE masking tests"""
    print("\n" + "="*60)
    print("SPARSE MOE MASKING TESTS - EDGE VALIDATION")
    print("Validating Thor's Session 52 Fix")
    print("="*60)

    results = []
    tests = [
        ("Sparse Masking Logic", test_sparse_masking_logic),
        ("Default Behavior", test_empty_mask_default),
        ("Qwen3-Omni Simulation", test_sparse_layer_simulation),
        ("SNARC Path Masking", test_snarc_path_masking),
        ("Edge Performance", test_edge_performance),
    ]

    for name, test_fn in tests:
        try:
            passed = test_fn()
            results.append((name, "PASS" if passed else "FAIL"))
        except Exception as e:
            print(f"\nâŒ FAIL: {e}")
            results.append((name, "FAIL"))

    # Summary
    print("\n" + "="*60)
    print("TEST SUMMARY")
    print("="*60)

    passed = sum(1 for _, r in results if r == "PASS")
    total = len(results)

    for name, result in results:
        status = "âœ…" if result == "PASS" else "âŒ"
        print(f"  {status} {name}: {result}")

    print(f"\nTotal: {passed}/{total} tests passed")

    if passed == total:
        print("\nðŸŽ‰ ALL TESTS PASS - Thor's sparse MoE fix validated on edge!")
    else:
        print(f"\nâš ï¸  {total - passed} test(s) failed")

    return passed == total


if __name__ == "__main__":
    run_all_tests()
