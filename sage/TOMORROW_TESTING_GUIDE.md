# Tomorrow's Testing Guide - Hybrid Learning System

## Quick Start

### Option 1: Threaded Dashboard (Recommended)
```bash
cd /home/sprout/ai-workspace/HRM/sage
python3 tests/hybrid_conversation_threaded.py --real-llm
```

**What to expect:**
- Dashboard updates smoothly in real-time (10x per second)
- Timestamps on state changes
- Pattern matching debug info
- Learning events visible as they happen

### Option 2: Original Version
```bash
cd /home/sprout/ai-workspace/HRM/sage
python3 tests/hybrid_conversation_realtime.py --real-llm
```

**What to expect:**
- Dashboard only updates on events
- May appear static between conversations
- Same learning functionality

## Testing Checklist

### 1. Dashboard Visual Test
- [ ] Dashboard renders and updates smoothly
- [ ] State changes visible (LISTENING â†’ THINKING â†’ SPEAKING)
- [ ] LLM processing state shows when slow path engaged
- [ ] Statistics update correctly
- [ ] Progress bar moves

### 2. Pattern Learning Test
Ask these questions in order:

**Round 1 (Novel - should use LLM):**
- "Tell me about black holes"
- "Explain photosynthesis"
- "What are fractals?"

**Round 2 (Repeat - learning happens):**
- "Tell me about black holes"
- "Explain photosynthesis"
- "What are fractals?"

**Round 3 (Learned - should use fast path):**
- "Tell me about black holes"
- "Explain photosynthesis"
- "What are fractals?"

**Expected behavior:**
- Round 1: All slow path (ðŸ§ )
- Round 2: All slow path (ðŸ§ ) + learning events (ðŸ“š)
- Round 3: All fast path (âš¡) using learned patterns

### 3. Pattern Confidence Gating
Try different confidence thresholds:

```bash
# Low threshold (more false positives)
python3 tests/hybrid_conversation_threaded.py --real-llm --confidence 0.5

# Medium threshold (balanced)
python3 tests/hybrid_conversation_threaded.py --real-llm --confidence 0.7

# High threshold (very conservative)
python3 tests/hybrid_conversation_threaded.py --real-llm --confidence 0.9
```

**Watch for:**
- Pattern rejection count in final stats
- Balance between fast/slow path
- Learning progression

### 4. Long Conversation Test
Have a 20+ question conversation and watch:
- [ ] Fast path ratio increasing over time
- [ ] New patterns being learned
- [ ] Progress bar filling up
- [ ] Response quality maintained

## Known Issues

### Issue 1: Default Patterns Too Broad
**Problem:** Some questions match default patterns too easily
**Evidence:** Test shows "quantum" and "neural network" questions hit fast path immediately
**Workaround:** Use --confidence 0.9 for more conservative matching
**Fix needed:** Review cognitive/pattern_responses.py and make patterns more specific

### Issue 2: Static Dashboard (Original Version)
**Problem:** Dashboard doesn't update between events
**Status:** FIXED in threaded version
**Solution:** Use hybrid_conversation_threaded.py instead

### Issue 3: Conversation History Format
**Problem:** History was being stored as dicts instead of tuples
**Status:** FIXED
**Evidence:** Commit 4e866c5

## Success Criteria

âœ… Dashboard updates in real-time during conversation
âœ… Both fast and slow paths engage appropriately
âœ… Pattern learning observable (new patterns added)
âœ… Fast path ratio increases from ~0% â†’ 50%+ over 20 questions
âœ… No TTS overlap (responses don't talk over each other)
âœ… LLM latency acceptable (2-5 seconds)
âœ… Clean visualization of learning process

## Performance Expectations

**Qwen 0.5B on CPU:**
- LLM latency: 2-5 seconds
- Fast path latency: <1ms
- Pattern learning: After 2 occurrences
- Dashboard refresh: 10 times per second

**Memory usage:**
- Qwen 0.5B: ~2GB RAM
- Conversation history: Last 5 turns
- Pattern storage: Minimal (<1MB)

## Files Overview

```
tests/
â”œâ”€â”€ hybrid_conversation_realtime.py      # Original (static dashboard)
â”œâ”€â”€ hybrid_conversation_threaded.py      # NEW: Threaded dashboard
â””â”€â”€ test_pattern_learning.py             # Validation test suite

cognitive/
â”œâ”€â”€ pattern_learner.py                   # Pattern extraction logic
â””â”€â”€ pattern_responses.py                 # Pattern matching engine

experiments/integration/
â””â”€â”€ phi2_responder.py                    # Qwen 0.5B LLM wrapper
```

## Debugging Commands

### Check if processes are running
```bash
ps aux | grep python3
```

### Kill stuck processes
```bash
pkill -f hybrid_conversation
```

### View recent log
```bash
tail -50 /tmp/hybrid_test.log
```

### Test pattern learning without audio
```bash
python3 tests/test_pattern_learning.py
```

## What We Achieved Today

1. âœ… **Hybrid Learning Integration**: Pattern matching + LLM + learning working together
2. âœ… **Real-time Audio**: Microphone â†’ Whisper â†’ TTS pipeline integrated
3. âœ… **Visual Dashboard**: Status visualization with stats and progress bar
4. âœ… **Threaded Updates**: Smooth real-time dashboard rendering
5. âœ… **Pattern Confidence**: Gating to prevent greedy matching
6. âœ… **Learning Validation**: Test suite proves learning works (69.2% efficiency)
7. âœ… **TTS Overlap Fix**: Duration-based blocking prevents conflicts
8. âœ… **Qwen 0.5B**: Smaller model running efficiently on CPU

## What's Left for Tomorrow

1. ðŸ”„ **Test threaded dashboard** with real audio (highest priority)
2. ðŸ”„ **Refine default patterns** to be more specific
3. ðŸ”„ **Validate learning** in live conversation
4. ðŸ”„ **Document everything** for future reference
5. ðŸ”„ **Consider web dashboard** if terminal UX insufficient

## Expected Timeline

- **5 min**: Launch threaded version, verify dashboard works
- **10 min**: Run pattern learning test with real questions
- **15 min**: Long conversation to watch learning progression
- **10 min**: Try different confidence thresholds
- **10 min**: Document findings and next steps

**Total: ~50 minutes of testing**

## Final Notes

The system is functionally complete. What remains is:
- Polish (default pattern tuning)
- Validation (real conversation testing)
- Documentation (usage guide)

The core concept is proven: **Consciousness can learn reflexes from experience.**
From 0% â†’ 69%+ fast path efficiency through pattern learning.
This is procedural memory development in real-time.

Have fun testing tomorrow! ðŸ§ âœ¨
