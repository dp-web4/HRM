#!/usr/bin/env python3
"""
SAGE Cascading Architecture: H-level as router, L-level as specialist heads
Inspired by the observation that Claude's "tool selection" reveals architectural patterns
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import List, Dict, Any, Tuple, Optional
from dataclasses import dataclass
from enum import Enum

class SpecialistType(Enum):
    """Types of L-level specialist heads"""
    SPATIAL_TRANSFORM = "spatial"      # Rotations, scaling, tiling
    COLOR_MAPPING = "color"           # Color transformations
    PATTERN_EXTRACTION = "extract"    # Finding/extracting objects
    PATTERN_COMPLETION = "complete"   # Filling, extending patterns
    COUNTING = "count"                # Counting operations
    LOGICAL = "logical"               # Boolean operations
    SEQUENCE = "sequence"             # Sequential patterns
    COMPOSITION = "compose"           # Combining multiple patterns

@dataclass
class RoutingDecision:
    """H-level's routing decision"""
    primary_specialist: SpecialistType
    secondary_specialists: List[SpecialistType]
    confidence: float
    context: Dict[str, Any]  # Context to pass to L-level
    attention_mask: torch.Tensor  # Which parts of input to focus on

class HLevelRouter(nn.Module):
    """
    H-level: Analyzes task and routes to appropriate L-level specialists
    This is like Claude's 'I need to use tool X for task Y' reasoning
    """
    
    def __init__(self, hidden_size: int = 256):
        super().__init__()
        self.hidden_size = hidden_size
        
        # Pattern analysis layers
        self.pattern_encoder = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(
                d_model=hidden_size,
                nhead=8,
                dim_feedforward=hidden_size * 4,
                batch_first=True
            ),
            num_layers=4  # H-layers in HRM terminology
        )
        
        # Classifier for specialist selection
        self.specialist_classifier = nn.Sequential(
            nn.Linear(hidden_size, hidden_size * 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_size * 2, len(SpecialistType))
        )
        
        # Context generator for L-level
        self.context_generator = nn.Linear(hidden_size, hidden_size)
        
        # Attention mask generator
        self.attention_generator = nn.Linear(hidden_size, 1)
        
    def forward(self, 
                input_tensor: torch.Tensor,
                examples: Optional[List[torch.Tensor]] = None) -> RoutingDecision:
        """
        Analyze input and route to specialists
        
        This is equivalent to Claude's process:
        1. "Looking at this task..."
        2. "I need to search for patterns..." 
        3. "I'll use the Grep tool..."
        """
        
        # Encode the pattern
        hidden = self.pattern_encoder(input_tensor)
        
        # Global representation for classification
        global_repr = hidden.mean(dim=1)  # [batch, hidden]
        
        # Classify which specialists are needed
        specialist_logits = self.specialist_classifier(global_repr)
        specialist_probs = F.softmax(specialist_logits, dim=-1)
        
        # Primary specialist (highest probability)
        primary_idx = specialist_probs.argmax(dim=-1).item()
        primary = list(SpecialistType)[primary_idx]
        
        # Secondary specialists (above threshold)
        threshold = 0.2
        secondary_indices = (specialist_probs > threshold).nonzero(as_tuple=True)[1]
        secondary = [list(SpecialistType)[idx] for idx in secondary_indices 
                    if idx != primary_idx]
        
        # Generate context for L-level
        context_vector = self.context_generator(global_repr)
        
        # Generate attention mask (where should L-level focus?)
        attention_scores = self.attention_generator(hidden).squeeze(-1)
        attention_mask = F.sigmoid(attention_scores)
        
        return RoutingDecision(
            primary_specialist=primary,
            secondary_specialists=secondary,
            confidence=specialist_probs[0, primary_idx].item(),
            context={'vector': context_vector, 'encoded': hidden},
            attention_mask=attention_mask
        )

class LLevelSpecialistHead(nn.Module):
    """
    Base class for L-level specialist heads
    Each specialist is like a specific tool in Claude's toolkit
    """
    
    def __init__(self, specialist_type: SpecialistType, hidden_size: int = 256):
        super().__init__()
        self.specialist_type = specialist_type
        self.hidden_size = hidden_size
        
        # Specialist-specific layers
        self.processor = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(
                d_model=hidden_size,
                nhead=4,  # Fewer heads for specialists
                dim_feedforward=hidden_size * 2,
                batch_first=True
            ),
            num_layers=3  # L-layers in HRM terminology
        )
        
    def forward(self, 
                input_tensor: torch.Tensor,
                context: Dict[str, Any],
                attention_mask: torch.Tensor) -> torch.Tensor:
        """Execute specialist transformation"""
        
        # Apply attention mask from H-level
        masked_input = input_tensor * attention_mask.unsqueeze(-1)
        
        # Process with specialist knowledge
        output = self.processor(masked_input)
        
        return output

class SpatialTransformHead(LLevelSpecialistHead):
    """Specialist for spatial transformations (rotation, scaling, tiling)"""
    
    def __init__(self, hidden_size: int = 256):
        super().__init__(SpecialistType.SPATIAL_TRANSFORM, hidden_size)
        
        # Specific layers for spatial reasoning
        self.spatial_analyzer = nn.Sequential(
            nn.Conv2d(1, 16, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(16, 32, 3, padding=1),
            nn.ReLU()
        )
        
        self.transform_predictor = nn.Linear(hidden_size, 9)  # 3x3 transform matrix

class ColorMappingHead(LLevelSpecialistHead):
    """Specialist for color transformations"""
    
    def __init__(self, hidden_size: int = 256, num_colors: int = 10):
        super().__init__(SpecialistType.COLOR_MAPPING, hidden_size)
        
        # Color mapping table
        self.color_map = nn.Parameter(torch.randn(num_colors, num_colors))
        
        # Learn mapping rules
        self.mapping_mlp = nn.Sequential(
            nn.Linear(hidden_size, num_colors * num_colors),
            nn.Unflatten(1, (num_colors, num_colors)),
            nn.Softmax(dim=-1)
        )

class SAGECascadingModel(nn.Module):
    """
    Complete SAGE model with cascading Hâ†’L architecture
    
    This mirrors Claude's actual process:
    1. Analyze task (H-level reasoning)
    2. Select appropriate tools (routing to specialists)
    3. Execute with specific capability (L-level specialists)
    """
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__()
        self.config = config
        
        # H-level router (the "reasoning" part)
        self.h_router = HLevelRouter(config['hidden_size'])
        
        # L-level specialist heads (the "tools")
        self.specialists = nn.ModuleDict({
            SpecialistType.SPATIAL_TRANSFORM.value: SpatialTransformHead(config['hidden_size']),
            SpecialistType.COLOR_MAPPING.value: ColorMappingHead(config['hidden_size']),
            # Add more specialists as needed
        })
        
        # Output combiner (when multiple specialists are active)
        self.output_combiner = nn.Linear(
            config['hidden_size'] * len(self.specialists),
            config['hidden_size']
        )
        
    def forward(self, 
                input_tensor: torch.Tensor,
                examples: Optional[List[torch.Tensor]] = None,
                verbose: bool = False) -> Tuple[torch.Tensor, Dict[str, Any]]:
        """
        Full cascading forward pass
        
        If verbose=True, returns the "reasoning trace" (like Claude's explanations)
        """
        
        # H-level: Analyze and route
        routing = self.h_router(input_tensor, examples)
        
        if verbose:
            print(f"H-level analysis: Primary specialist = {routing.primary_specialist}")
            print(f"Confidence: {routing.confidence:.2f}")
            if routing.secondary_specialists:
                print(f"Secondary specialists: {routing.secondary_specialists}")
        
        # L-level: Execute with selected specialists
        outputs = []
        
        # Primary specialist
        if routing.primary_specialist.value in self.specialists:
            specialist = self.specialists[routing.primary_specialist.value]
            primary_output = specialist(input_tensor, routing.context, routing.attention_mask)
            outputs.append(primary_output)
            
            if verbose:
                print(f"Executing {routing.primary_specialist.value}...")
        
        # Secondary specialists (if confidence suggests multi-pattern)
        for secondary in routing.secondary_specialists:
            if secondary.value in self.specialists:
                specialist = self.specialists[secondary.value]
                secondary_output = specialist(input_tensor, routing.context, routing.attention_mask)
                outputs.append(secondary_output)
                
                if verbose:
                    print(f"Also applying {secondary.value}...")
        
        # Combine outputs if multiple specialists
        if len(outputs) > 1:
            combined = torch.cat(outputs, dim=-1)
            final_output = self.output_combiner(combined)
        else:
            final_output = outputs[0] if outputs else input_tensor
        
        # Return output and routing decision (the "reasoning trace")
        return final_output, {
            'routing': routing,
            'num_specialists_used': len(outputs),
            'specialists_used': [routing.primary_specialist] + routing.secondary_specialists
        }

def demonstrate_cascading():
    """
    Demonstrate how the cascading architecture works
    Similar to how Claude selects tools and explains reasoning
    """
    
    config = {
        'hidden_size': 256,
        'vocab_size': 12,  # ARC colors
        'max_size': 30
    }
    
    model = SAGECascadingModel(config)
    
    # Simulate an ARC-like input
    batch_size = 1
    seq_len = 900  # 30x30 flattened
    hidden_size = config['hidden_size']
    
    # Random input (would be encoded ARC grid in practice)
    input_tensor = torch.randn(batch_size, seq_len, hidden_size)
    
    # Forward pass with verbose reasoning
    print("SAGE Cascading Architecture Demo")
    print("=" * 50)
    
    output, reasoning = model(input_tensor, verbose=True)
    
    print("\nReasoning trace:")
    print(f"- Used {reasoning['num_specialists_used']} specialists")
    print(f"- Specialists: {[s.value for s in reasoning['specialists_used']]}")
    print(f"- Output shape: {output.shape}")
    
    return model, output, reasoning

if __name__ == "__main__":
    # This demonstrates the key insight:
    # What appears as "theatrical reasoning" in Claude is actually
    # the H-level router selecting L-level specialists!
    
    print("""
    Key Insight: Claude's 'tool selection' process reveals the architecture:
    
    1. H-level analyzes: "Looking at this task..."
    2. H-level routes: "I need to use Grep/Read/Edit..."  
    3. L-level executes: Specialist heads handle specific operations
    4. Results combine: Multiple specialists can contribute
    
    This isn't theater - it's the actual routing mechanism!
    """)
    
    model, output, reasoning = demonstrate_cascading()
    
    print("\nArchitectural Implications:")
    print("- No monolithic L-level, but specialist attention heads")
    print("- H-level acts as classifier/router")
    print("- Context and attention masks cascade down")
    print("- The 'reasoning trace' IS the architecture in action!")