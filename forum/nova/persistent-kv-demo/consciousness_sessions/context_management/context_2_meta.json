{
  "session_id": "context_management",
  "timestamp": "2025-08-28T19:07:51.269054",
  "model": "gpt2",
  "conversation_length": 2,
  "kv_shape": "torch.Size([1, 12, 20, 64])",
  "history": [
    {
      "timestamp": "2025-08-28T19:07:51.262302",
      "input": "In quantum mechanics, observation collapses the wave function.",
      "kv_seq_len": 10
    },
    {
      "timestamp": "2025-08-28T19:07:51.267307",
      "input": "Similarly, in transformer models, attention creates meaning.",
      "kv_seq_len": 20
    }
  ]
}