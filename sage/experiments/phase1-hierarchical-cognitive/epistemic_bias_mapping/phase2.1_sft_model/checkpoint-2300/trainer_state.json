{
  "best_global_step": 138,
  "best_metric": 2.555018186569214,
  "best_model_checkpoint": "./phase2.1_sft_model/checkpoint-138",
  "epoch": 50.0,
  "eval_steps": 500,
  "global_step": 2300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.21739130434782608,
      "grad_norm": 7.761688709259033,
      "learning_rate": 0.00012,
      "loss": 4.0036,
      "step": 10
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 2.971457004547119,
      "learning_rate": 0.0001994759825327511,
      "loss": 2.766,
      "step": 20
    },
    {
      "epoch": 0.6521739130434783,
      "grad_norm": 2.226116418838501,
      "learning_rate": 0.00019860262008733625,
      "loss": 3.119,
      "step": 30
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 2.4818053245544434,
      "learning_rate": 0.00019772925764192142,
      "loss": 2.7498,
      "step": 40
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.7026853561401367,
      "eval_runtime": 0.7144,
      "eval_samples_per_second": 32.196,
      "eval_steps_per_second": 16.798,
      "step": 46
    },
    {
      "epoch": 1.0869565217391304,
      "grad_norm": 2.6084227561950684,
      "learning_rate": 0.00019685589519650656,
      "loss": 2.3706,
      "step": 50
    },
    {
      "epoch": 1.3043478260869565,
      "grad_norm": 2.171638011932373,
      "learning_rate": 0.0001959825327510917,
      "loss": 2.6297,
      "step": 60
    },
    {
      "epoch": 1.5217391304347827,
      "grad_norm": 2.9011056423187256,
      "learning_rate": 0.00019510917030567685,
      "loss": 2.4901,
      "step": 70
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 2.540109157562256,
      "learning_rate": 0.00019423580786026202,
      "loss": 2.1739,
      "step": 80
    },
    {
      "epoch": 1.9565217391304348,
      "grad_norm": 2.9651942253112793,
      "learning_rate": 0.00019336244541484716,
      "loss": 2.4272,
      "step": 90
    },
    {
      "epoch": 2.0,
      "eval_loss": 2.567946672439575,
      "eval_runtime": 0.5132,
      "eval_samples_per_second": 44.814,
      "eval_steps_per_second": 23.381,
      "step": 92
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 3.03120756149292,
      "learning_rate": 0.00019248908296943233,
      "loss": 2.0153,
      "step": 100
    },
    {
      "epoch": 2.391304347826087,
      "grad_norm": 3.068660259246826,
      "learning_rate": 0.00019161572052401747,
      "loss": 2.0357,
      "step": 110
    },
    {
      "epoch": 2.608695652173913,
      "grad_norm": 3.2728774547576904,
      "learning_rate": 0.00019074235807860264,
      "loss": 2.131,
      "step": 120
    },
    {
      "epoch": 2.8260869565217392,
      "grad_norm": 4.229684352874756,
      "learning_rate": 0.00018986899563318778,
      "loss": 2.2445,
      "step": 130
    },
    {
      "epoch": 3.0,
      "eval_loss": 2.555018186569214,
      "eval_runtime": 0.5175,
      "eval_samples_per_second": 44.443,
      "eval_steps_per_second": 23.188,
      "step": 138
    },
    {
      "epoch": 3.0434782608695654,
      "grad_norm": 2.7707762718200684,
      "learning_rate": 0.00018899563318777293,
      "loss": 1.9323,
      "step": 140
    },
    {
      "epoch": 3.260869565217391,
      "grad_norm": 4.224023342132568,
      "learning_rate": 0.0001881222707423581,
      "loss": 1.7891,
      "step": 150
    },
    {
      "epoch": 3.4782608695652173,
      "grad_norm": 4.245892524719238,
      "learning_rate": 0.00018724890829694324,
      "loss": 1.9669,
      "step": 160
    },
    {
      "epoch": 3.6956521739130435,
      "grad_norm": 4.987171649932861,
      "learning_rate": 0.00018637554585152838,
      "loss": 1.65,
      "step": 170
    },
    {
      "epoch": 3.9130434782608696,
      "grad_norm": 4.264621257781982,
      "learning_rate": 0.00018550218340611353,
      "loss": 2.0299,
      "step": 180
    },
    {
      "epoch": 4.0,
      "eval_loss": 2.614361047744751,
      "eval_runtime": 0.5085,
      "eval_samples_per_second": 45.233,
      "eval_steps_per_second": 23.6,
      "step": 184
    },
    {
      "epoch": 4.130434782608695,
      "grad_norm": 4.145445823669434,
      "learning_rate": 0.0001846288209606987,
      "loss": 1.6011,
      "step": 190
    },
    {
      "epoch": 4.3478260869565215,
      "grad_norm": 5.25996208190918,
      "learning_rate": 0.00018375545851528387,
      "loss": 1.5629,
      "step": 200
    },
    {
      "epoch": 4.565217391304348,
      "grad_norm": 5.313851356506348,
      "learning_rate": 0.000182882096069869,
      "loss": 1.6688,
      "step": 210
    },
    {
      "epoch": 4.782608695652174,
      "grad_norm": 6.474913597106934,
      "learning_rate": 0.00018200873362445418,
      "loss": 1.5158,
      "step": 220
    },
    {
      "epoch": 5.0,
      "grad_norm": 4.350371360778809,
      "learning_rate": 0.00018113537117903932,
      "loss": 1.5482,
      "step": 230
    },
    {
      "epoch": 5.0,
      "eval_loss": 2.724642515182495,
      "eval_runtime": 0.5124,
      "eval_samples_per_second": 44.887,
      "eval_steps_per_second": 23.419,
      "step": 230
    },
    {
      "epoch": 5.217391304347826,
      "grad_norm": 6.329213619232178,
      "learning_rate": 0.00018026200873362446,
      "loss": 1.398,
      "step": 240
    },
    {
      "epoch": 5.434782608695652,
      "grad_norm": 5.387973785400391,
      "learning_rate": 0.0001793886462882096,
      "loss": 1.0291,
      "step": 250
    },
    {
      "epoch": 5.6521739130434785,
      "grad_norm": 5.476752281188965,
      "learning_rate": 0.00017851528384279478,
      "loss": 1.4733,
      "step": 260
    },
    {
      "epoch": 5.869565217391305,
      "grad_norm": 12.520944595336914,
      "learning_rate": 0.00017764192139737992,
      "loss": 1.4086,
      "step": 270
    },
    {
      "epoch": 6.0,
      "eval_loss": 2.8685574531555176,
      "eval_runtime": 0.5132,
      "eval_samples_per_second": 44.821,
      "eval_steps_per_second": 23.385,
      "step": 276
    },
    {
      "epoch": 6.086956521739131,
      "grad_norm": 7.656341552734375,
      "learning_rate": 0.00017676855895196506,
      "loss": 1.2957,
      "step": 280
    },
    {
      "epoch": 6.304347826086957,
      "grad_norm": 9.660340309143066,
      "learning_rate": 0.00017589519650655023,
      "loss": 1.027,
      "step": 290
    },
    {
      "epoch": 6.521739130434782,
      "grad_norm": 6.9625420570373535,
      "learning_rate": 0.00017502183406113537,
      "loss": 1.1094,
      "step": 300
    },
    {
      "epoch": 6.739130434782608,
      "grad_norm": 6.432622909545898,
      "learning_rate": 0.00017414847161572054,
      "loss": 1.1484,
      "step": 310
    },
    {
      "epoch": 6.956521739130435,
      "grad_norm": 4.079780578613281,
      "learning_rate": 0.00017327510917030569,
      "loss": 1.0138,
      "step": 320
    },
    {
      "epoch": 7.0,
      "eval_loss": 3.016594648361206,
      "eval_runtime": 0.4864,
      "eval_samples_per_second": 47.286,
      "eval_steps_per_second": 24.671,
      "step": 322
    },
    {
      "epoch": 7.173913043478261,
      "grad_norm": 6.7944793701171875,
      "learning_rate": 0.00017240174672489086,
      "loss": 1.1051,
      "step": 330
    },
    {
      "epoch": 7.391304347826087,
      "grad_norm": 6.771420001983643,
      "learning_rate": 0.000171528384279476,
      "loss": 0.8232,
      "step": 340
    },
    {
      "epoch": 7.608695652173913,
      "grad_norm": 8.161694526672363,
      "learning_rate": 0.00017065502183406114,
      "loss": 0.934,
      "step": 350
    },
    {
      "epoch": 7.826086956521739,
      "grad_norm": 7.430149078369141,
      "learning_rate": 0.00016978165938864628,
      "loss": 0.8028,
      "step": 360
    },
    {
      "epoch": 8.0,
      "eval_loss": 3.233431577682495,
      "eval_runtime": 0.5155,
      "eval_samples_per_second": 44.615,
      "eval_steps_per_second": 23.277,
      "step": 368
    },
    {
      "epoch": 8.043478260869565,
      "grad_norm": 6.660760402679443,
      "learning_rate": 0.00016890829694323145,
      "loss": 0.9478,
      "step": 370
    },
    {
      "epoch": 8.26086956521739,
      "grad_norm": 6.1626691818237305,
      "learning_rate": 0.0001680349344978166,
      "loss": 0.8945,
      "step": 380
    },
    {
      "epoch": 8.478260869565217,
      "grad_norm": 9.84860897064209,
      "learning_rate": 0.00016716157205240174,
      "loss": 0.7779,
      "step": 390
    },
    {
      "epoch": 8.695652173913043,
      "grad_norm": 5.116676330566406,
      "learning_rate": 0.0001662882096069869,
      "loss": 0.6329,
      "step": 400
    },
    {
      "epoch": 8.91304347826087,
      "grad_norm": 4.621917724609375,
      "learning_rate": 0.00016541484716157205,
      "loss": 0.6524,
      "step": 410
    },
    {
      "epoch": 9.0,
      "eval_loss": 3.5116591453552246,
      "eval_runtime": 0.5108,
      "eval_samples_per_second": 45.03,
      "eval_steps_per_second": 23.494,
      "step": 414
    },
    {
      "epoch": 9.130434782608695,
      "grad_norm": 11.108263969421387,
      "learning_rate": 0.00016454148471615722,
      "loss": 0.6073,
      "step": 420
    },
    {
      "epoch": 9.347826086956522,
      "grad_norm": 8.354911804199219,
      "learning_rate": 0.00016366812227074236,
      "loss": 0.6002,
      "step": 430
    },
    {
      "epoch": 9.565217391304348,
      "grad_norm": 9.411234855651855,
      "learning_rate": 0.00016279475982532753,
      "loss": 0.5481,
      "step": 440
    },
    {
      "epoch": 9.782608695652174,
      "grad_norm": 6.698393821716309,
      "learning_rate": 0.00016192139737991268,
      "loss": 0.5409,
      "step": 450
    },
    {
      "epoch": 10.0,
      "grad_norm": 6.206968784332275,
      "learning_rate": 0.00016104803493449782,
      "loss": 0.6881,
      "step": 460
    },
    {
      "epoch": 10.0,
      "eval_loss": 3.693441390991211,
      "eval_runtime": 0.5248,
      "eval_samples_per_second": 43.829,
      "eval_steps_per_second": 22.867,
      "step": 460
    },
    {
      "epoch": 10.217391304347826,
      "grad_norm": 3.3770525455474854,
      "learning_rate": 0.000160174672489083,
      "loss": 0.4177,
      "step": 470
    },
    {
      "epoch": 10.434782608695652,
      "grad_norm": 6.0104241371154785,
      "learning_rate": 0.00015930131004366813,
      "loss": 0.3801,
      "step": 480
    },
    {
      "epoch": 10.652173913043478,
      "grad_norm": 7.796191215515137,
      "learning_rate": 0.00015842794759825328,
      "loss": 0.5963,
      "step": 490
    },
    {
      "epoch": 10.869565217391305,
      "grad_norm": 5.2190022468566895,
      "learning_rate": 0.00015755458515283842,
      "loss": 0.4913,
      "step": 500
    },
    {
      "epoch": 11.0,
      "eval_loss": 3.9226489067077637,
      "eval_runtime": 0.4915,
      "eval_samples_per_second": 46.8,
      "eval_steps_per_second": 24.417,
      "step": 506
    },
    {
      "epoch": 11.08695652173913,
      "grad_norm": 6.501244068145752,
      "learning_rate": 0.0001566812227074236,
      "loss": 0.5023,
      "step": 510
    },
    {
      "epoch": 11.304347826086957,
      "grad_norm": 11.996432304382324,
      "learning_rate": 0.00015580786026200873,
      "loss": 0.3629,
      "step": 520
    },
    {
      "epoch": 11.521739130434783,
      "grad_norm": 11.258050918579102,
      "learning_rate": 0.0001549344978165939,
      "loss": 0.435,
      "step": 530
    },
    {
      "epoch": 11.73913043478261,
      "grad_norm": 8.753335952758789,
      "learning_rate": 0.00015406113537117904,
      "loss": 0.3545,
      "step": 540
    },
    {
      "epoch": 11.956521739130435,
      "grad_norm": 4.549770355224609,
      "learning_rate": 0.0001531877729257642,
      "loss": 0.3927,
      "step": 550
    },
    {
      "epoch": 12.0,
      "eval_loss": 4.121959686279297,
      "eval_runtime": 0.4857,
      "eval_samples_per_second": 47.35,
      "eval_steps_per_second": 24.704,
      "step": 552
    },
    {
      "epoch": 12.173913043478262,
      "grad_norm": 11.363149642944336,
      "learning_rate": 0.00015231441048034936,
      "loss": 0.2931,
      "step": 560
    },
    {
      "epoch": 12.391304347826088,
      "grad_norm": 7.522349834442139,
      "learning_rate": 0.0001514410480349345,
      "loss": 0.3003,
      "step": 570
    },
    {
      "epoch": 12.608695652173914,
      "grad_norm": 9.487828254699707,
      "learning_rate": 0.00015056768558951967,
      "loss": 0.3733,
      "step": 580
    },
    {
      "epoch": 12.826086956521738,
      "grad_norm": 6.968694686889648,
      "learning_rate": 0.0001496943231441048,
      "loss": 0.3409,
      "step": 590
    },
    {
      "epoch": 13.0,
      "eval_loss": 4.185247898101807,
      "eval_runtime": 0.5195,
      "eval_samples_per_second": 44.277,
      "eval_steps_per_second": 23.101,
      "step": 598
    },
    {
      "epoch": 13.043478260869565,
      "grad_norm": 6.558916091918945,
      "learning_rate": 0.00014882096069868995,
      "loss": 0.371,
      "step": 600
    },
    {
      "epoch": 13.26086956521739,
      "grad_norm": 11.277466773986816,
      "learning_rate": 0.00014794759825327512,
      "loss": 0.2499,
      "step": 610
    },
    {
      "epoch": 13.478260869565217,
      "grad_norm": 9.366941452026367,
      "learning_rate": 0.00014707423580786027,
      "loss": 0.261,
      "step": 620
    },
    {
      "epoch": 13.695652173913043,
      "grad_norm": 6.65194845199585,
      "learning_rate": 0.0001462008733624454,
      "loss": 0.2677,
      "step": 630
    },
    {
      "epoch": 13.91304347826087,
      "grad_norm": 6.679421901702881,
      "learning_rate": 0.00014532751091703058,
      "loss": 0.2859,
      "step": 640
    },
    {
      "epoch": 14.0,
      "eval_loss": 4.466800212860107,
      "eval_runtime": 0.4948,
      "eval_samples_per_second": 46.483,
      "eval_steps_per_second": 24.252,
      "step": 644
    },
    {
      "epoch": 14.130434782608695,
      "grad_norm": 9.493877410888672,
      "learning_rate": 0.00014445414847161575,
      "loss": 0.2418,
      "step": 650
    },
    {
      "epoch": 14.347826086956522,
      "grad_norm": 6.6618266105651855,
      "learning_rate": 0.0001435807860262009,
      "loss": 0.2033,
      "step": 660
    },
    {
      "epoch": 14.565217391304348,
      "grad_norm": 8.713422775268555,
      "learning_rate": 0.00014270742358078603,
      "loss": 0.1932,
      "step": 670
    },
    {
      "epoch": 14.782608695652174,
      "grad_norm": 4.89639949798584,
      "learning_rate": 0.00014183406113537118,
      "loss": 0.2527,
      "step": 680
    },
    {
      "epoch": 15.0,
      "grad_norm": 12.773380279541016,
      "learning_rate": 0.00014096069868995635,
      "loss": 0.253,
      "step": 690
    },
    {
      "epoch": 15.0,
      "eval_loss": 4.425559997558594,
      "eval_runtime": 2.6355,
      "eval_samples_per_second": 8.727,
      "eval_steps_per_second": 4.553,
      "step": 690
    },
    {
      "epoch": 15.217391304347826,
      "grad_norm": 5.846904277801514,
      "learning_rate": 0.0001400873362445415,
      "loss": 0.1694,
      "step": 700
    },
    {
      "epoch": 15.434782608695652,
      "grad_norm": 3.6330721378326416,
      "learning_rate": 0.00013921397379912663,
      "loss": 0.21,
      "step": 710
    },
    {
      "epoch": 15.652173913043478,
      "grad_norm": 7.660222053527832,
      "learning_rate": 0.0001383406113537118,
      "loss": 0.182,
      "step": 720
    },
    {
      "epoch": 15.869565217391305,
      "grad_norm": 7.336811065673828,
      "learning_rate": 0.00013746724890829695,
      "loss": 0.2185,
      "step": 730
    },
    {
      "epoch": 16.0,
      "eval_loss": 4.592437267303467,
      "eval_runtime": 0.9925,
      "eval_samples_per_second": 23.173,
      "eval_steps_per_second": 12.09,
      "step": 736
    },
    {
      "epoch": 16.08695652173913,
      "grad_norm": 2.362745523452759,
      "learning_rate": 0.0001365938864628821,
      "loss": 0.1749,
      "step": 740
    },
    {
      "epoch": 16.304347826086957,
      "grad_norm": 6.869340896606445,
      "learning_rate": 0.00013572052401746726,
      "loss": 0.1471,
      "step": 750
    },
    {
      "epoch": 16.52173913043478,
      "grad_norm": 12.138326644897461,
      "learning_rate": 0.00013484716157205243,
      "loss": 0.2014,
      "step": 760
    },
    {
      "epoch": 16.73913043478261,
      "grad_norm": 8.5249662399292,
      "learning_rate": 0.00013397379912663757,
      "loss": 0.1891,
      "step": 770
    },
    {
      "epoch": 16.956521739130434,
      "grad_norm": 7.834200859069824,
      "learning_rate": 0.0001331004366812227,
      "loss": 0.1786,
      "step": 780
    },
    {
      "epoch": 17.0,
      "eval_loss": 4.594954013824463,
      "eval_runtime": 0.9477,
      "eval_samples_per_second": 24.269,
      "eval_steps_per_second": 12.662,
      "step": 782
    },
    {
      "epoch": 17.17391304347826,
      "grad_norm": 4.141824245452881,
      "learning_rate": 0.00013222707423580786,
      "loss": 0.1495,
      "step": 790
    },
    {
      "epoch": 17.391304347826086,
      "grad_norm": 5.282057285308838,
      "learning_rate": 0.00013135371179039303,
      "loss": 0.1681,
      "step": 800
    },
    {
      "epoch": 17.608695652173914,
      "grad_norm": 4.75465726852417,
      "learning_rate": 0.00013048034934497817,
      "loss": 0.1516,
      "step": 810
    },
    {
      "epoch": 17.82608695652174,
      "grad_norm": 4.717046737670898,
      "learning_rate": 0.0001296069868995633,
      "loss": 0.1652,
      "step": 820
    },
    {
      "epoch": 18.0,
      "eval_loss": 4.784036159515381,
      "eval_runtime": 0.5155,
      "eval_samples_per_second": 44.62,
      "eval_steps_per_second": 23.28,
      "step": 828
    },
    {
      "epoch": 18.043478260869566,
      "grad_norm": 4.075305938720703,
      "learning_rate": 0.00012873362445414848,
      "loss": 0.1377,
      "step": 830
    },
    {
      "epoch": 18.26086956521739,
      "grad_norm": 8.042701721191406,
      "learning_rate": 0.00012786026200873362,
      "loss": 0.13,
      "step": 840
    },
    {
      "epoch": 18.47826086956522,
      "grad_norm": 4.756228923797607,
      "learning_rate": 0.00012698689956331877,
      "loss": 0.1257,
      "step": 850
    },
    {
      "epoch": 18.695652173913043,
      "grad_norm": 10.393814086914062,
      "learning_rate": 0.00012611353711790394,
      "loss": 0.1581,
      "step": 860
    },
    {
      "epoch": 18.91304347826087,
      "grad_norm": 6.088869571685791,
      "learning_rate": 0.0001252401746724891,
      "loss": 0.146,
      "step": 870
    },
    {
      "epoch": 19.0,
      "eval_loss": 4.728871822357178,
      "eval_runtime": 0.5189,
      "eval_samples_per_second": 44.326,
      "eval_steps_per_second": 23.127,
      "step": 874
    },
    {
      "epoch": 19.130434782608695,
      "grad_norm": 5.742163181304932,
      "learning_rate": 0.00012436681222707425,
      "loss": 0.1273,
      "step": 880
    },
    {
      "epoch": 19.347826086956523,
      "grad_norm": 1.77695894241333,
      "learning_rate": 0.0001234934497816594,
      "loss": 0.1092,
      "step": 890
    },
    {
      "epoch": 19.565217391304348,
      "grad_norm": 6.960184574127197,
      "learning_rate": 0.00012262008733624456,
      "loss": 0.1221,
      "step": 900
    },
    {
      "epoch": 19.782608695652176,
      "grad_norm": 3.1539440155029297,
      "learning_rate": 0.0001217467248908297,
      "loss": 0.125,
      "step": 910
    },
    {
      "epoch": 20.0,
      "grad_norm": 7.490480422973633,
      "learning_rate": 0.00012087336244541485,
      "loss": 0.1384,
      "step": 920
    },
    {
      "epoch": 20.0,
      "eval_loss": 4.894108772277832,
      "eval_runtime": 0.5242,
      "eval_samples_per_second": 43.878,
      "eval_steps_per_second": 22.893,
      "step": 920
    },
    {
      "epoch": 20.217391304347824,
      "grad_norm": 11.557951927185059,
      "learning_rate": 0.00012,
      "loss": 0.1138,
      "step": 930
    },
    {
      "epoch": 20.434782608695652,
      "grad_norm": 3.731440782546997,
      "learning_rate": 0.00011912663755458515,
      "loss": 0.1107,
      "step": 940
    },
    {
      "epoch": 20.652173913043477,
      "grad_norm": 6.332463264465332,
      "learning_rate": 0.0001182532751091703,
      "loss": 0.1121,
      "step": 950
    },
    {
      "epoch": 20.869565217391305,
      "grad_norm": 6.554256439208984,
      "learning_rate": 0.00011737991266375546,
      "loss": 0.1262,
      "step": 960
    },
    {
      "epoch": 21.0,
      "eval_loss": 4.9687581062316895,
      "eval_runtime": 0.5166,
      "eval_samples_per_second": 44.518,
      "eval_steps_per_second": 23.227,
      "step": 966
    },
    {
      "epoch": 21.08695652173913,
      "grad_norm": 1.7785600423812866,
      "learning_rate": 0.00011650655021834063,
      "loss": 0.1104,
      "step": 970
    },
    {
      "epoch": 21.304347826086957,
      "grad_norm": 4.4258198738098145,
      "learning_rate": 0.00011563318777292577,
      "loss": 0.1106,
      "step": 980
    },
    {
      "epoch": 21.52173913043478,
      "grad_norm": 2.4951813220977783,
      "learning_rate": 0.00011475982532751093,
      "loss": 0.1098,
      "step": 990
    },
    {
      "epoch": 21.73913043478261,
      "grad_norm": 3.9671647548675537,
      "learning_rate": 0.00011388646288209608,
      "loss": 0.1018,
      "step": 1000
    },
    {
      "epoch": 21.956521739130434,
      "grad_norm": 1.973117470741272,
      "learning_rate": 0.00011301310043668123,
      "loss": 0.1122,
      "step": 1010
    },
    {
      "epoch": 22.0,
      "eval_loss": 4.938329696655273,
      "eval_runtime": 0.523,
      "eval_samples_per_second": 43.978,
      "eval_steps_per_second": 22.945,
      "step": 1012
    },
    {
      "epoch": 22.17391304347826,
      "grad_norm": 2.1873226165771484,
      "learning_rate": 0.00011213973799126638,
      "loss": 0.0958,
      "step": 1020
    },
    {
      "epoch": 22.391304347826086,
      "grad_norm": 1.7791987657546997,
      "learning_rate": 0.00011126637554585153,
      "loss": 0.0938,
      "step": 1030
    },
    {
      "epoch": 22.608695652173914,
      "grad_norm": 7.898941993713379,
      "learning_rate": 0.00011039301310043668,
      "loss": 0.0934,
      "step": 1040
    },
    {
      "epoch": 22.82608695652174,
      "grad_norm": 1.7680422067642212,
      "learning_rate": 0.00010951965065502184,
      "loss": 0.099,
      "step": 1050
    },
    {
      "epoch": 23.0,
      "eval_loss": 5.269669055938721,
      "eval_runtime": 0.4921,
      "eval_samples_per_second": 46.735,
      "eval_steps_per_second": 24.384,
      "step": 1058
    },
    {
      "epoch": 23.043478260869566,
      "grad_norm": 1.4827558994293213,
      "learning_rate": 0.00010864628820960698,
      "loss": 0.1086,
      "step": 1060
    },
    {
      "epoch": 23.26086956521739,
      "grad_norm": 1.9718493223190308,
      "learning_rate": 0.00010777292576419214,
      "loss": 0.0875,
      "step": 1070
    },
    {
      "epoch": 23.47826086956522,
      "grad_norm": 3.117095708847046,
      "learning_rate": 0.0001068995633187773,
      "loss": 0.0862,
      "step": 1080
    },
    {
      "epoch": 23.695652173913043,
      "grad_norm": 1.0847223997116089,
      "learning_rate": 0.00010602620087336246,
      "loss": 0.0914,
      "step": 1090
    },
    {
      "epoch": 23.91304347826087,
      "grad_norm": 3.1683053970336914,
      "learning_rate": 0.0001051528384279476,
      "loss": 0.0994,
      "step": 1100
    },
    {
      "epoch": 24.0,
      "eval_loss": 5.267355918884277,
      "eval_runtime": 0.5184,
      "eval_samples_per_second": 44.367,
      "eval_steps_per_second": 23.148,
      "step": 1104
    },
    {
      "epoch": 24.130434782608695,
      "grad_norm": 1.521915078163147,
      "learning_rate": 0.00010427947598253276,
      "loss": 0.0855,
      "step": 1110
    },
    {
      "epoch": 24.347826086956523,
      "grad_norm": 1.1424813270568848,
      "learning_rate": 0.0001034061135371179,
      "loss": 0.0795,
      "step": 1120
    },
    {
      "epoch": 24.565217391304348,
      "grad_norm": 1.3538696765899658,
      "learning_rate": 0.00010253275109170306,
      "loss": 0.0904,
      "step": 1130
    },
    {
      "epoch": 24.782608695652176,
      "grad_norm": 0.7375046610832214,
      "learning_rate": 0.00010165938864628822,
      "loss": 0.0961,
      "step": 1140
    },
    {
      "epoch": 25.0,
      "grad_norm": 4.243194103240967,
      "learning_rate": 0.00010078602620087336,
      "loss": 0.0887,
      "step": 1150
    },
    {
      "epoch": 25.0,
      "eval_loss": 5.244001388549805,
      "eval_runtime": 0.5198,
      "eval_samples_per_second": 44.247,
      "eval_steps_per_second": 23.086,
      "step": 1150
    },
    {
      "epoch": 25.217391304347824,
      "grad_norm": 1.5288317203521729,
      "learning_rate": 9.991266375545853e-05,
      "loss": 0.0815,
      "step": 1160
    },
    {
      "epoch": 25.434782608695652,
      "grad_norm": 1.4709279537200928,
      "learning_rate": 9.903930131004367e-05,
      "loss": 0.0822,
      "step": 1170
    },
    {
      "epoch": 25.652173913043477,
      "grad_norm": 2.7013137340545654,
      "learning_rate": 9.816593886462883e-05,
      "loss": 0.0849,
      "step": 1180
    },
    {
      "epoch": 25.869565217391305,
      "grad_norm": 2.301192283630371,
      "learning_rate": 9.729257641921397e-05,
      "loss": 0.0818,
      "step": 1190
    },
    {
      "epoch": 26.0,
      "eval_loss": 5.232010364532471,
      "eval_runtime": 0.5301,
      "eval_samples_per_second": 43.391,
      "eval_steps_per_second": 22.639,
      "step": 1196
    },
    {
      "epoch": 26.08695652173913,
      "grad_norm": 0.9671644568443298,
      "learning_rate": 9.641921397379913e-05,
      "loss": 0.0799,
      "step": 1200
    },
    {
      "epoch": 26.304347826086957,
      "grad_norm": 1.235473871231079,
      "learning_rate": 9.554585152838428e-05,
      "loss": 0.0708,
      "step": 1210
    },
    {
      "epoch": 26.52173913043478,
      "grad_norm": 2.249992609024048,
      "learning_rate": 9.467248908296944e-05,
      "loss": 0.0909,
      "step": 1220
    },
    {
      "epoch": 26.73913043478261,
      "grad_norm": 2.9129810333251953,
      "learning_rate": 9.37991266375546e-05,
      "loss": 0.0889,
      "step": 1230
    },
    {
      "epoch": 26.956521739130434,
      "grad_norm": 2.6154582500457764,
      "learning_rate": 9.292576419213974e-05,
      "loss": 0.0799,
      "step": 1240
    },
    {
      "epoch": 27.0,
      "eval_loss": 5.328115463256836,
      "eval_runtime": 2.6651,
      "eval_samples_per_second": 8.63,
      "eval_steps_per_second": 4.503,
      "step": 1242
    },
    {
      "epoch": 27.17391304347826,
      "grad_norm": 0.9943441152572632,
      "learning_rate": 9.20524017467249e-05,
      "loss": 0.0762,
      "step": 1250
    },
    {
      "epoch": 27.391304347826086,
      "grad_norm": 2.028787612915039,
      "learning_rate": 9.117903930131004e-05,
      "loss": 0.0718,
      "step": 1260
    },
    {
      "epoch": 27.608695652173914,
      "grad_norm": 1.9414499998092651,
      "learning_rate": 9.030567685589521e-05,
      "loss": 0.0832,
      "step": 1270
    },
    {
      "epoch": 27.82608695652174,
      "grad_norm": 0.9100365042686462,
      "learning_rate": 8.943231441048035e-05,
      "loss": 0.0809,
      "step": 1280
    },
    {
      "epoch": 28.0,
      "eval_loss": 5.4017229080200195,
      "eval_runtime": 1.0248,
      "eval_samples_per_second": 22.442,
      "eval_steps_per_second": 11.709,
      "step": 1288
    },
    {
      "epoch": 28.043478260869566,
      "grad_norm": 0.8576199412345886,
      "learning_rate": 8.855895196506551e-05,
      "loss": 0.0757,
      "step": 1290
    },
    {
      "epoch": 28.26086956521739,
      "grad_norm": 1.4379043579101562,
      "learning_rate": 8.768558951965066e-05,
      "loss": 0.0698,
      "step": 1300
    },
    {
      "epoch": 28.47826086956522,
      "grad_norm": 3.4658262729644775,
      "learning_rate": 8.68122270742358e-05,
      "loss": 0.0807,
      "step": 1310
    },
    {
      "epoch": 28.695652173913043,
      "grad_norm": 1.372756838798523,
      "learning_rate": 8.593886462882098e-05,
      "loss": 0.0796,
      "step": 1320
    },
    {
      "epoch": 28.91304347826087,
      "grad_norm": 2.4042840003967285,
      "learning_rate": 8.506550218340612e-05,
      "loss": 0.0793,
      "step": 1330
    },
    {
      "epoch": 29.0,
      "eval_loss": 5.519443035125732,
      "eval_runtime": 0.9427,
      "eval_samples_per_second": 24.397,
      "eval_steps_per_second": 12.729,
      "step": 1334
    },
    {
      "epoch": 29.130434782608695,
      "grad_norm": 1.0681020021438599,
      "learning_rate": 8.419213973799128e-05,
      "loss": 0.0672,
      "step": 1340
    },
    {
      "epoch": 29.347826086956523,
      "grad_norm": 1.0235633850097656,
      "learning_rate": 8.331877729257642e-05,
      "loss": 0.0685,
      "step": 1350
    },
    {
      "epoch": 29.565217391304348,
      "grad_norm": 1.1842713356018066,
      "learning_rate": 8.244541484716157e-05,
      "loss": 0.0768,
      "step": 1360
    },
    {
      "epoch": 29.782608695652176,
      "grad_norm": 1.1434321403503418,
      "learning_rate": 8.157205240174672e-05,
      "loss": 0.0727,
      "step": 1370
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.7811888456344604,
      "learning_rate": 8.069868995633189e-05,
      "loss": 0.0815,
      "step": 1380
    },
    {
      "epoch": 30.0,
      "eval_loss": 5.364032745361328,
      "eval_runtime": 0.518,
      "eval_samples_per_second": 44.398,
      "eval_steps_per_second": 23.164,
      "step": 1380
    },
    {
      "epoch": 30.217391304347824,
      "grad_norm": 1.2684359550476074,
      "learning_rate": 7.982532751091703e-05,
      "loss": 0.0724,
      "step": 1390
    },
    {
      "epoch": 30.434782608695652,
      "grad_norm": 1.0307416915893555,
      "learning_rate": 7.895196506550219e-05,
      "loss": 0.0662,
      "step": 1400
    },
    {
      "epoch": 30.652173913043477,
      "grad_norm": 0.7497654557228088,
      "learning_rate": 7.807860262008734e-05,
      "loss": 0.0721,
      "step": 1410
    },
    {
      "epoch": 30.869565217391305,
      "grad_norm": 0.8365196585655212,
      "learning_rate": 7.720524017467248e-05,
      "loss": 0.0701,
      "step": 1420
    },
    {
      "epoch": 31.0,
      "eval_loss": 5.362791061401367,
      "eval_runtime": 0.4935,
      "eval_samples_per_second": 46.608,
      "eval_steps_per_second": 24.317,
      "step": 1426
    },
    {
      "epoch": 31.08695652173913,
      "grad_norm": 0.7051464915275574,
      "learning_rate": 7.633187772925765e-05,
      "loss": 0.0683,
      "step": 1430
    },
    {
      "epoch": 31.304347826086957,
      "grad_norm": 2.6066837310791016,
      "learning_rate": 7.54585152838428e-05,
      "loss": 0.068,
      "step": 1440
    },
    {
      "epoch": 31.52173913043478,
      "grad_norm": 1.3740636110305786,
      "learning_rate": 7.458515283842795e-05,
      "loss": 0.0726,
      "step": 1450
    },
    {
      "epoch": 31.73913043478261,
      "grad_norm": 0.7469480037689209,
      "learning_rate": 7.37117903930131e-05,
      "loss": 0.0674,
      "step": 1460
    },
    {
      "epoch": 31.956521739130434,
      "grad_norm": 0.8987457156181335,
      "learning_rate": 7.283842794759825e-05,
      "loss": 0.0716,
      "step": 1470
    },
    {
      "epoch": 32.0,
      "eval_loss": 5.63504695892334,
      "eval_runtime": 0.4917,
      "eval_samples_per_second": 46.776,
      "eval_steps_per_second": 24.405,
      "step": 1472
    },
    {
      "epoch": 32.17391304347826,
      "grad_norm": 1.0424067974090576,
      "learning_rate": 7.196506550218341e-05,
      "loss": 0.0594,
      "step": 1480
    },
    {
      "epoch": 32.391304347826086,
      "grad_norm": 1.0482109785079956,
      "learning_rate": 7.109170305676857e-05,
      "loss": 0.0614,
      "step": 1490
    },
    {
      "epoch": 32.608695652173914,
      "grad_norm": 0.8703963756561279,
      "learning_rate": 7.021834061135372e-05,
      "loss": 0.0689,
      "step": 1500
    },
    {
      "epoch": 32.82608695652174,
      "grad_norm": 0.6448789238929749,
      "learning_rate": 6.934497816593886e-05,
      "loss": 0.0717,
      "step": 1510
    },
    {
      "epoch": 33.0,
      "eval_loss": 5.500316619873047,
      "eval_runtime": 0.5257,
      "eval_samples_per_second": 43.753,
      "eval_steps_per_second": 22.828,
      "step": 1518
    },
    {
      "epoch": 33.04347826086956,
      "grad_norm": 0.8879584074020386,
      "learning_rate": 6.847161572052402e-05,
      "loss": 0.0653,
      "step": 1520
    },
    {
      "epoch": 33.26086956521739,
      "grad_norm": 0.697131872177124,
      "learning_rate": 6.759825327510916e-05,
      "loss": 0.0612,
      "step": 1530
    },
    {
      "epoch": 33.47826086956522,
      "grad_norm": 0.893036425113678,
      "learning_rate": 6.672489082969433e-05,
      "loss": 0.0649,
      "step": 1540
    },
    {
      "epoch": 33.69565217391305,
      "grad_norm": 0.9617055058479309,
      "learning_rate": 6.585152838427948e-05,
      "loss": 0.0647,
      "step": 1550
    },
    {
      "epoch": 33.91304347826087,
      "grad_norm": 1.1454169750213623,
      "learning_rate": 6.497816593886463e-05,
      "loss": 0.0665,
      "step": 1560
    },
    {
      "epoch": 34.0,
      "eval_loss": 5.6463942527771,
      "eval_runtime": 0.4928,
      "eval_samples_per_second": 46.674,
      "eval_steps_per_second": 24.352,
      "step": 1564
    },
    {
      "epoch": 34.130434782608695,
      "grad_norm": 1.0158822536468506,
      "learning_rate": 6.410480349344979e-05,
      "loss": 0.0627,
      "step": 1570
    },
    {
      "epoch": 34.34782608695652,
      "grad_norm": 0.8433331251144409,
      "learning_rate": 6.323144104803493e-05,
      "loss": 0.0608,
      "step": 1580
    },
    {
      "epoch": 34.56521739130435,
      "grad_norm": 1.1801899671554565,
      "learning_rate": 6.23580786026201e-05,
      "loss": 0.0633,
      "step": 1590
    },
    {
      "epoch": 34.78260869565217,
      "grad_norm": 1.2583149671554565,
      "learning_rate": 6.148471615720524e-05,
      "loss": 0.0695,
      "step": 1600
    },
    {
      "epoch": 35.0,
      "grad_norm": 0.951835036277771,
      "learning_rate": 6.06113537117904e-05,
      "loss": 0.063,
      "step": 1610
    },
    {
      "epoch": 35.0,
      "eval_loss": 5.638227939605713,
      "eval_runtime": 0.5172,
      "eval_samples_per_second": 44.474,
      "eval_steps_per_second": 23.204,
      "step": 1610
    },
    {
      "epoch": 35.21739130434783,
      "grad_norm": 0.7255565524101257,
      "learning_rate": 5.973799126637555e-05,
      "loss": 0.0547,
      "step": 1620
    },
    {
      "epoch": 35.43478260869565,
      "grad_norm": 1.3300822973251343,
      "learning_rate": 5.88646288209607e-05,
      "loss": 0.0654,
      "step": 1630
    },
    {
      "epoch": 35.65217391304348,
      "grad_norm": 1.0442651510238647,
      "learning_rate": 5.799126637554585e-05,
      "loss": 0.0622,
      "step": 1640
    },
    {
      "epoch": 35.869565217391305,
      "grad_norm": 0.9292877912521362,
      "learning_rate": 5.711790393013101e-05,
      "loss": 0.0631,
      "step": 1650
    },
    {
      "epoch": 36.0,
      "eval_loss": 5.664315223693848,
      "eval_runtime": 0.5053,
      "eval_samples_per_second": 45.515,
      "eval_steps_per_second": 23.747,
      "step": 1656
    },
    {
      "epoch": 36.08695652173913,
      "grad_norm": 0.9816555976867676,
      "learning_rate": 5.624454148471616e-05,
      "loss": 0.0657,
      "step": 1660
    },
    {
      "epoch": 36.30434782608695,
      "grad_norm": 0.9087566137313843,
      "learning_rate": 5.537117903930131e-05,
      "loss": 0.0564,
      "step": 1670
    },
    {
      "epoch": 36.52173913043478,
      "grad_norm": 1.1958224773406982,
      "learning_rate": 5.449781659388646e-05,
      "loss": 0.0608,
      "step": 1680
    },
    {
      "epoch": 36.73913043478261,
      "grad_norm": 1.2623345851898193,
      "learning_rate": 5.362445414847162e-05,
      "loss": 0.0642,
      "step": 1690
    },
    {
      "epoch": 36.95652173913044,
      "grad_norm": 0.8918794989585876,
      "learning_rate": 5.275109170305678e-05,
      "loss": 0.064,
      "step": 1700
    },
    {
      "epoch": 37.0,
      "eval_loss": 5.639854907989502,
      "eval_runtime": 0.5012,
      "eval_samples_per_second": 45.89,
      "eval_steps_per_second": 23.943,
      "step": 1702
    },
    {
      "epoch": 37.17391304347826,
      "grad_norm": 0.9074084758758545,
      "learning_rate": 5.187772925764193e-05,
      "loss": 0.0561,
      "step": 1710
    },
    {
      "epoch": 37.391304347826086,
      "grad_norm": 1.351316213607788,
      "learning_rate": 5.100436681222708e-05,
      "loss": 0.0586,
      "step": 1720
    },
    {
      "epoch": 37.608695652173914,
      "grad_norm": 1.046101689338684,
      "learning_rate": 5.013100436681223e-05,
      "loss": 0.06,
      "step": 1730
    },
    {
      "epoch": 37.82608695652174,
      "grad_norm": 0.8536778092384338,
      "learning_rate": 4.9257641921397385e-05,
      "loss": 0.06,
      "step": 1740
    },
    {
      "epoch": 38.0,
      "eval_loss": 5.795798301696777,
      "eval_runtime": 0.4923,
      "eval_samples_per_second": 46.722,
      "eval_steps_per_second": 24.377,
      "step": 1748
    },
    {
      "epoch": 38.04347826086956,
      "grad_norm": 0.6381226778030396,
      "learning_rate": 4.8384279475982534e-05,
      "loss": 0.0661,
      "step": 1750
    },
    {
      "epoch": 38.26086956521739,
      "grad_norm": 0.7580022811889648,
      "learning_rate": 4.7510917030567684e-05,
      "loss": 0.0549,
      "step": 1760
    },
    {
      "epoch": 38.47826086956522,
      "grad_norm": 1.2411439418792725,
      "learning_rate": 4.663755458515284e-05,
      "loss": 0.0585,
      "step": 1770
    },
    {
      "epoch": 38.69565217391305,
      "grad_norm": 1.1115387678146362,
      "learning_rate": 4.5764192139737996e-05,
      "loss": 0.0629,
      "step": 1780
    },
    {
      "epoch": 38.91304347826087,
      "grad_norm": 1.0406067371368408,
      "learning_rate": 4.4890829694323146e-05,
      "loss": 0.0624,
      "step": 1790
    },
    {
      "epoch": 39.0,
      "eval_loss": 5.741381645202637,
      "eval_runtime": 1.0701,
      "eval_samples_per_second": 21.492,
      "eval_steps_per_second": 11.213,
      "step": 1794
    },
    {
      "epoch": 39.130434782608695,
      "grad_norm": 0.6572529673576355,
      "learning_rate": 4.40174672489083e-05,
      "loss": 0.0573,
      "step": 1800
    },
    {
      "epoch": 39.34782608695652,
      "grad_norm": 0.7013369202613831,
      "learning_rate": 4.314410480349345e-05,
      "loss": 0.055,
      "step": 1810
    },
    {
      "epoch": 39.56521739130435,
      "grad_norm": 0.7956592440605164,
      "learning_rate": 4.22707423580786e-05,
      "loss": 0.0609,
      "step": 1820
    },
    {
      "epoch": 39.78260869565217,
      "grad_norm": 1.3354604244232178,
      "learning_rate": 4.139737991266376e-05,
      "loss": 0.0602,
      "step": 1830
    },
    {
      "epoch": 40.0,
      "grad_norm": 1.377052903175354,
      "learning_rate": 4.052401746724891e-05,
      "loss": 0.0631,
      "step": 1840
    },
    {
      "epoch": 40.0,
      "eval_loss": 5.760241985321045,
      "eval_runtime": 2.5206,
      "eval_samples_per_second": 9.125,
      "eval_steps_per_second": 4.761,
      "step": 1840
    },
    {
      "epoch": 40.21739130434783,
      "grad_norm": 0.941114604473114,
      "learning_rate": 3.965065502183406e-05,
      "loss": 0.0544,
      "step": 1850
    },
    {
      "epoch": 40.43478260869565,
      "grad_norm": 0.7935014367103577,
      "learning_rate": 3.877729257641922e-05,
      "loss": 0.0565,
      "step": 1860
    },
    {
      "epoch": 40.65217391304348,
      "grad_norm": 0.8869300484657288,
      "learning_rate": 3.790393013100437e-05,
      "loss": 0.057,
      "step": 1870
    },
    {
      "epoch": 40.869565217391305,
      "grad_norm": 1.234753131866455,
      "learning_rate": 3.7030567685589525e-05,
      "loss": 0.0602,
      "step": 1880
    },
    {
      "epoch": 41.0,
      "eval_loss": 5.835897922515869,
      "eval_runtime": 0.9957,
      "eval_samples_per_second": 23.099,
      "eval_steps_per_second": 12.052,
      "step": 1886
    },
    {
      "epoch": 41.08695652173913,
      "grad_norm": 0.7499051690101624,
      "learning_rate": 3.6157205240174675e-05,
      "loss": 0.0576,
      "step": 1890
    },
    {
      "epoch": 41.30434782608695,
      "grad_norm": 0.583743691444397,
      "learning_rate": 3.5283842794759824e-05,
      "loss": 0.0544,
      "step": 1900
    },
    {
      "epoch": 41.52173913043478,
      "grad_norm": 0.6146705746650696,
      "learning_rate": 3.441048034934498e-05,
      "loss": 0.0559,
      "step": 1910
    },
    {
      "epoch": 41.73913043478261,
      "grad_norm": 0.7999165654182434,
      "learning_rate": 3.353711790393013e-05,
      "loss": 0.0588,
      "step": 1920
    },
    {
      "epoch": 41.95652173913044,
      "grad_norm": 1.204634428024292,
      "learning_rate": 3.266375545851528e-05,
      "loss": 0.0639,
      "step": 1930
    },
    {
      "epoch": 42.0,
      "eval_loss": 5.874737739562988,
      "eval_runtime": 0.5111,
      "eval_samples_per_second": 44.999,
      "eval_steps_per_second": 23.478,
      "step": 1932
    },
    {
      "epoch": 42.17391304347826,
      "grad_norm": 0.7356077432632446,
      "learning_rate": 3.1790393013100436e-05,
      "loss": 0.0528,
      "step": 1940
    },
    {
      "epoch": 42.391304347826086,
      "grad_norm": 1.0963809490203857,
      "learning_rate": 3.091703056768559e-05,
      "loss": 0.0563,
      "step": 1950
    },
    {
      "epoch": 42.608695652173914,
      "grad_norm": 1.0328691005706787,
      "learning_rate": 3.0043668122270745e-05,
      "loss": 0.0558,
      "step": 1960
    },
    {
      "epoch": 42.82608695652174,
      "grad_norm": 1.1197348833084106,
      "learning_rate": 2.9170305676855898e-05,
      "loss": 0.0603,
      "step": 1970
    },
    {
      "epoch": 43.0,
      "eval_loss": 5.855916500091553,
      "eval_runtime": 0.5185,
      "eval_samples_per_second": 44.358,
      "eval_steps_per_second": 23.143,
      "step": 1978
    },
    {
      "epoch": 43.04347826086956,
      "grad_norm": 0.8137487173080444,
      "learning_rate": 2.8296943231441047e-05,
      "loss": 0.0607,
      "step": 1980
    },
    {
      "epoch": 43.26086956521739,
      "grad_norm": 1.0116676092147827,
      "learning_rate": 2.7423580786026204e-05,
      "loss": 0.0539,
      "step": 1990
    },
    {
      "epoch": 43.47826086956522,
      "grad_norm": 0.974949300289154,
      "learning_rate": 2.6550218340611353e-05,
      "loss": 0.0533,
      "step": 2000
    },
    {
      "epoch": 43.69565217391305,
      "grad_norm": 1.0632693767547607,
      "learning_rate": 2.5676855895196506e-05,
      "loss": 0.0573,
      "step": 2010
    },
    {
      "epoch": 43.91304347826087,
      "grad_norm": 1.210908055305481,
      "learning_rate": 2.4803493449781662e-05,
      "loss": 0.0583,
      "step": 2020
    },
    {
      "epoch": 44.0,
      "eval_loss": 5.852956295013428,
      "eval_runtime": 0.5213,
      "eval_samples_per_second": 44.119,
      "eval_steps_per_second": 23.019,
      "step": 2024
    },
    {
      "epoch": 44.130434782608695,
      "grad_norm": 0.8100966215133667,
      "learning_rate": 2.3930131004366812e-05,
      "loss": 0.0564,
      "step": 2030
    },
    {
      "epoch": 44.34782608695652,
      "grad_norm": 0.8078767657279968,
      "learning_rate": 2.3056768558951965e-05,
      "loss": 0.0566,
      "step": 2040
    },
    {
      "epoch": 44.56521739130435,
      "grad_norm": 0.879189670085907,
      "learning_rate": 2.218340611353712e-05,
      "loss": 0.0531,
      "step": 2050
    },
    {
      "epoch": 44.78260869565217,
      "grad_norm": 0.6480844020843506,
      "learning_rate": 2.131004366812227e-05,
      "loss": 0.0564,
      "step": 2060
    },
    {
      "epoch": 45.0,
      "grad_norm": 1.0184621810913086,
      "learning_rate": 2.0436681222707423e-05,
      "loss": 0.0573,
      "step": 2070
    },
    {
      "epoch": 45.0,
      "eval_loss": 5.8741655349731445,
      "eval_runtime": 0.5143,
      "eval_samples_per_second": 44.72,
      "eval_steps_per_second": 23.332,
      "step": 2070
    },
    {
      "epoch": 45.21739130434783,
      "grad_norm": 0.7864476442337036,
      "learning_rate": 1.9563318777292576e-05,
      "loss": 0.0517,
      "step": 2080
    },
    {
      "epoch": 45.43478260869565,
      "grad_norm": 0.6969917416572571,
      "learning_rate": 1.868995633187773e-05,
      "loss": 0.0563,
      "step": 2090
    },
    {
      "epoch": 45.65217391304348,
      "grad_norm": 0.8620176911354065,
      "learning_rate": 1.7816593886462882e-05,
      "loss": 0.0571,
      "step": 2100
    },
    {
      "epoch": 45.869565217391305,
      "grad_norm": 0.7670618891716003,
      "learning_rate": 1.6943231441048035e-05,
      "loss": 0.0525,
      "step": 2110
    },
    {
      "epoch": 46.0,
      "eval_loss": 5.910195350646973,
      "eval_runtime": 0.5203,
      "eval_samples_per_second": 44.209,
      "eval_steps_per_second": 23.066,
      "step": 2116
    },
    {
      "epoch": 46.08695652173913,
      "grad_norm": 0.8190139532089233,
      "learning_rate": 1.6069868995633188e-05,
      "loss": 0.0541,
      "step": 2120
    },
    {
      "epoch": 46.30434782608695,
      "grad_norm": 1.0735373497009277,
      "learning_rate": 1.5196506550218343e-05,
      "loss": 0.0504,
      "step": 2130
    },
    {
      "epoch": 46.52173913043478,
      "grad_norm": 0.9273710250854492,
      "learning_rate": 1.4323144104803494e-05,
      "loss": 0.0552,
      "step": 2140
    },
    {
      "epoch": 46.73913043478261,
      "grad_norm": 0.911237895488739,
      "learning_rate": 1.3449781659388647e-05,
      "loss": 0.0518,
      "step": 2150
    },
    {
      "epoch": 46.95652173913044,
      "grad_norm": 0.8436903953552246,
      "learning_rate": 1.25764192139738e-05,
      "loss": 0.0593,
      "step": 2160
    },
    {
      "epoch": 47.0,
      "eval_loss": 5.905924320220947,
      "eval_runtime": 0.5237,
      "eval_samples_per_second": 43.919,
      "eval_steps_per_second": 22.914,
      "step": 2162
    },
    {
      "epoch": 47.17391304347826,
      "grad_norm": 0.8275992274284363,
      "learning_rate": 1.1703056768558952e-05,
      "loss": 0.0521,
      "step": 2170
    },
    {
      "epoch": 47.391304347826086,
      "grad_norm": 1.0653162002563477,
      "learning_rate": 1.0829694323144105e-05,
      "loss": 0.057,
      "step": 2180
    },
    {
      "epoch": 47.608695652173914,
      "grad_norm": 0.710986852645874,
      "learning_rate": 9.956331877729258e-06,
      "loss": 0.0528,
      "step": 2190
    },
    {
      "epoch": 47.82608695652174,
      "grad_norm": 0.9373789429664612,
      "learning_rate": 9.082969432314411e-06,
      "loss": 0.0564,
      "step": 2200
    },
    {
      "epoch": 48.0,
      "eval_loss": 5.889012336730957,
      "eval_runtime": 0.5273,
      "eval_samples_per_second": 43.619,
      "eval_steps_per_second": 22.758,
      "step": 2208
    },
    {
      "epoch": 48.04347826086956,
      "grad_norm": 0.6963254809379578,
      "learning_rate": 8.209606986899564e-06,
      "loss": 0.0515,
      "step": 2210
    },
    {
      "epoch": 48.26086956521739,
      "grad_norm": 0.7747364640235901,
      "learning_rate": 7.336244541484716e-06,
      "loss": 0.0496,
      "step": 2220
    },
    {
      "epoch": 48.47826086956522,
      "grad_norm": 0.8377284407615662,
      "learning_rate": 6.462882096069869e-06,
      "loss": 0.0535,
      "step": 2230
    },
    {
      "epoch": 48.69565217391305,
      "grad_norm": 0.8971951007843018,
      "learning_rate": 5.589519650655022e-06,
      "loss": 0.0532,
      "step": 2240
    },
    {
      "epoch": 48.91304347826087,
      "grad_norm": 0.8457720875740051,
      "learning_rate": 4.716157205240175e-06,
      "loss": 0.0556,
      "step": 2250
    },
    {
      "epoch": 49.0,
      "eval_loss": 5.906743049621582,
      "eval_runtime": 0.5274,
      "eval_samples_per_second": 43.608,
      "eval_steps_per_second": 22.752,
      "step": 2254
    },
    {
      "epoch": 49.130434782608695,
      "grad_norm": 0.6771528720855713,
      "learning_rate": 3.842794759825328e-06,
      "loss": 0.0534,
      "step": 2260
    },
    {
      "epoch": 49.34782608695652,
      "grad_norm": 0.6202594041824341,
      "learning_rate": 2.9694323144104802e-06,
      "loss": 0.0502,
      "step": 2270
    },
    {
      "epoch": 49.56521739130435,
      "grad_norm": 1.0034639835357666,
      "learning_rate": 2.096069868995633e-06,
      "loss": 0.0533,
      "step": 2280
    },
    {
      "epoch": 49.78260869565217,
      "grad_norm": 1.0101956129074097,
      "learning_rate": 1.222707423580786e-06,
      "loss": 0.0526,
      "step": 2290
    },
    {
      "epoch": 50.0,
      "grad_norm": 0.7019942402839661,
      "learning_rate": 3.4934497816593887e-07,
      "loss": 0.0557,
      "step": 2300
    },
    {
      "epoch": 50.0,
      "eval_loss": 5.9068827629089355,
      "eval_runtime": 0.5398,
      "eval_samples_per_second": 42.605,
      "eval_steps_per_second": 22.229,
      "step": 2300
    }
  ],
  "logging_steps": 10,
  "max_steps": 2300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5072810488627200.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
