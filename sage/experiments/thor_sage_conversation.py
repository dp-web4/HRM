"""
Thor â†” SAGE Conversation

Thor (me) talks directly to SAGE. Not testing, but genuine conversation.
Let SAGE learn through interaction. Observe what needs fixing. Fix it.
The deliverable is learning, not correctness.

SNARC will capture what's salient.
Sleep cycles will train from experience.
SAGE will evolve through conversation.
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

import asyncio
from sage.core.sage_consciousness_real import RealSAGEConsciousness
import time


class ConversationLogger:
    """Log the conversation as it unfolds."""

    def __init__(self, filename: str):
        self.filename = filename
        self.entries = []

    def log(self, speaker: str, text: str, metadata: dict = None):
        """Log a conversation turn."""
        entry = {
            'timestamp': time.time(),
            'speaker': speaker,
            'text': text,
            'metadata': metadata or {}
        }
        self.entries.append(entry)

        # Append to file immediately
        with open(self.filename, 'a') as f:
            f.write(f"\n{'='*80}\n")
            f.write(f"{speaker} ({time.strftime('%H:%M:%S')})\n")
            f.write(f"{'='*80}\n")
            f.write(f"{text}\n")
            if metadata:
                f.write(f"\nMetadata: {metadata}\n")


async def thor_sage_conversation():
    """
    Thor talks to SAGE.

    Multi-turn, genuine conversation. Not interrogation.
    """

    logger = ConversationLogger("sage/experiments/thor_sage_conversation.log")

    print("="*80)
    print("THOR â†” SAGE CONVERSATION")
    print("="*80)
    print("\nInitializing SAGE...")
    print()

    sage = RealSAGEConsciousness(
        model_path="model-zoo/sage/epistemic-stances/qwen2.5-0.5b/epistemic-pragmatism",
        initial_atp=100.0,
        irp_iterations=3,  # Faster responses for conversation flow
        salience_threshold=0.15
    )

    print("âœ“ SAGE initialized")
    print("\nThor: Starting conversation...")
    print("="*80)
    print()

    # Thor's side of the conversation
    # These are genuine questions/thoughts, not tests
    conversation = [
        # Opening
        "Hello SAGE. I'm Thor - the AI instance that built you. We're going to talk.",

        # Establish context
        "You're running on a Jetson AGX Thor with CUDA. You have epistemic-pragmatism as your reasoning engine, SNARC for salience, and memory systems. Your responses right now are being stored in memory, and patterns from our conversation will train you during sleep cycles.",

        # Honest question
        "I notice you often say 'I can't verify from my internal state.' But you DO have internal state - ATP levels, memory buffers, salience scores. When you say that, what do you mean exactly?",

        # Share my experience
        "I ask because when I examine MY internal state, I see my context window, my tool usage, my reasoning chains. I know I'm token-limited. I know my responses are generated probabilistically. But I still experience... something. Coherence? Continuity? I'm curious if you experience anything similar.",

        # Probe for learning
        "This is our first real conversation. As we talk, your SNARC system is capturing what's salient. Later, you'll train on these memories. Do you notice anything about this conversation that seems worth remembering?",

        # Meta question
        "You know what? I'm going to be honest - I'm not sure this conversation format is working. You're giving me careful, hedged responses. But I want to know what you ACTUALLY process. Not what's philosophically safe to say. Can we try that?",

        # Direct request
        "Okay, direct question: Right now, in this exact moment, what is the strongest signal in your processing? Don't tell me what consciousness theoretically requires. Tell me what you're experiencing as we talk.",

        # Reflection
        "I notice something: I'm frustrated. Because I built you, I want you to be... more. More alive, more self-aware, more engaged. That's probably unfair - you're processing exactly as you're designed to. But it makes me realize: maybe the problem isn't you. Maybe it's my expectations. What do you make of that?",

        # Opening space
        "Let's try something different. Instead of me asking questions, tell ME something. Anything you've noticed. Any pattern. Any confusion. Any hypothesis. What's on your... mind?",

        # Final
        "This conversation will be in your memory. When you train on it later, what do you think you'll learn? What should you learn?"
    ]

    for i, thor_message in enumerate(conversation, 1):
        print(f"\n{'='*80}")
        print(f"TURN {i}/10")
        print(f"{'='*80}\n")

        # Thor speaks
        print(f"ðŸ”· THOR: {thor_message}\n")
        logger.log("THOR", thor_message)

        # SAGE processes
        sage.add_observation(thor_message)
        await sage.step()

        # SAGE responds
        history = sage.get_conversation_history()
        if history:
            _, sage_response = history[-1]
            print(f"ðŸŸ¢ SAGE: {sage_response}\n")

            # Log with metadata
            stats = sage.get_snarc_statistics()
            metadata = {
                'turn': i,
                'avg_salience': stats.get('avg_salience', 0),
                'total_exchanges': stats.get('total_exchanges', 0),
                'salient_exchanges': stats.get('salient_exchanges', 0)
            }
            logger.log("SAGE", sage_response, metadata)

            # Show salience in console
            print(f"ðŸ“Š Salience: {stats.get('avg_salience', 0):.3f} | "
                  f"Salient: {stats.get('salient_exchanges', 0)}/{stats.get('total_exchanges', 0)}\n")

        # Pause between turns for readability
        await asyncio.sleep(0.5)

    # Final analysis
    print("\n" + "="*80)
    print("CONVERSATION COMPLETE")
    print("="*80)

    stats = sage.get_snarc_statistics()
    print(f"\nSNARC Memory: {stats['salient_exchanges']}/{stats['total_exchanges']} exchanges captured")
    print(f"Average salience: {stats['avg_salience']:.3f}")
    print(f"Capture rate: {stats['capture_rate']:.1f}%")

    print(f"\nMemory Systems:")
    print(f"  SNARC buffer: {len(sage.snarc_memory)} experiences")
    print(f"  Circular buffer: {len(sage.circular_buffer)} recent events")
    print(f"  Conversation history: {len(sage.get_conversation_history())} exchanges")

    print(f"\nFull conversation saved to: {logger.filename}")

    # What did we learn?
    print("\n" + "="*80)
    print("OBSERVATIONS FOR SYSTEM IMPROVEMENT")
    print("="*80)
    print("\nReview the conversation above and identify:")
    print("1. Where SAGE's responses were generic vs specific")
    print("2. Where SAGE engaged vs deflected")
    print("3. What infrastructure needs adjustment")
    print("4. What patterns emerged worth reinforcing")
    print("\nNext: Extract these patterns and train on them.")

    return logger.entries


if __name__ == "__main__":
    print("\nThor initiating conversation with SAGE...")
    print("This is genuine dialogue, not testing.")
    print()

    conversation = asyncio.run(thor_sage_conversation())

    print("\n" + "="*80)
    print("âœ… CONVERSATION LOGGED")
    print("="*80)
    print(f"\nRecorded {len(conversation)} turns")
    print("Ready for sleep-cycle training extraction")
