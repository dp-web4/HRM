{
  "best_global_step": null,
  "best_metric": Infinity,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 460,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.10869565217391304,
      "grad_norm": NaN,
      "learning_rate": 4.95108695652174e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.3812,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 10
    },
    {
      "epoch": 0.21739130434782608,
      "grad_norm": NaN,
      "learning_rate": 4.896739130434783e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 20
    },
    {
      "epoch": 0.32608695652173914,
      "grad_norm": NaN,
      "learning_rate": 4.842391304347827e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 30
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": NaN,
      "learning_rate": 4.78804347826087e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 40
    },
    {
      "epoch": 0.5434782608695652,
      "grad_norm": NaN,
      "learning_rate": 4.733695652173914e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 50
    },
    {
      "epoch": 0.6521739130434783,
      "grad_norm": NaN,
      "learning_rate": 4.679347826086957e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 60
    },
    {
      "epoch": 0.7608695652173914,
      "grad_norm": NaN,
      "learning_rate": 4.625000000000001e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 70
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": NaN,
      "learning_rate": 4.570652173913044e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 80
    },
    {
      "epoch": 0.9782608695652174,
      "grad_norm": NaN,
      "learning_rate": 4.516304347826087e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 90
    },
    {
      "epoch": 1.0,
      "eval_logits/chosen": NaN,
      "eval_logits/rejected": NaN,
      "eval_logps/chosen": NaN,
      "eval_logps/rejected": NaN,
      "eval_loss": NaN,
      "eval_rewards/accuracies": 0.0,
      "eval_rewards/chosen": NaN,
      "eval_rewards/margins": NaN,
      "eval_rewards/rejected": NaN,
      "eval_runtime": 0.7774,
      "eval_samples_per_second": 29.585,
      "eval_steps_per_second": 29.585,
      "step": 92
    },
    {
      "epoch": 1.0869565217391304,
      "grad_norm": NaN,
      "learning_rate": 4.461956521739131e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 100
    },
    {
      "epoch": 1.1956521739130435,
      "grad_norm": NaN,
      "learning_rate": 4.407608695652174e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 110
    },
    {
      "epoch": 1.3043478260869565,
      "grad_norm": NaN,
      "learning_rate": 4.353260869565218e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 120
    },
    {
      "epoch": 1.4130434782608696,
      "grad_norm": NaN,
      "learning_rate": 4.2989130434782615e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 130
    },
    {
      "epoch": 1.5217391304347827,
      "grad_norm": NaN,
      "learning_rate": 4.244565217391305e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 140
    },
    {
      "epoch": 1.6304347826086958,
      "grad_norm": NaN,
      "learning_rate": 4.1902173913043485e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 150
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": NaN,
      "learning_rate": 4.135869565217392e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 160
    },
    {
      "epoch": 1.8478260869565217,
      "grad_norm": NaN,
      "learning_rate": 4.0815217391304354e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 170
    },
    {
      "epoch": 1.9565217391304348,
      "grad_norm": NaN,
      "learning_rate": 4.027173913043478e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 180
    },
    {
      "epoch": 2.0,
      "eval_logits/chosen": NaN,
      "eval_logits/rejected": NaN,
      "eval_logps/chosen": NaN,
      "eval_logps/rejected": NaN,
      "eval_loss": NaN,
      "eval_rewards/accuracies": 0.0,
      "eval_rewards/chosen": NaN,
      "eval_rewards/margins": NaN,
      "eval_rewards/rejected": NaN,
      "eval_runtime": 0.7597,
      "eval_samples_per_second": 30.277,
      "eval_steps_per_second": 30.277,
      "step": 184
    },
    {
      "epoch": 2.0652173913043477,
      "grad_norm": NaN,
      "learning_rate": 3.972826086956522e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 190
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": NaN,
      "learning_rate": 3.918478260869565e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 200
    },
    {
      "epoch": 2.282608695652174,
      "grad_norm": NaN,
      "learning_rate": 3.864130434782609e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 210
    },
    {
      "epoch": 2.391304347826087,
      "grad_norm": NaN,
      "learning_rate": 3.8097826086956524e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 220
    },
    {
      "epoch": 2.5,
      "grad_norm": NaN,
      "learning_rate": 3.7554347826086963e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 230
    },
    {
      "epoch": 2.608695652173913,
      "grad_norm": NaN,
      "learning_rate": 3.7010869565217394e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 240
    },
    {
      "epoch": 2.717391304347826,
      "grad_norm": NaN,
      "learning_rate": 3.646739130434783e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 250
    },
    {
      "epoch": 2.8260869565217392,
      "grad_norm": NaN,
      "learning_rate": 3.5923913043478264e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 260
    },
    {
      "epoch": 2.9347826086956523,
      "grad_norm": NaN,
      "learning_rate": 3.53804347826087e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 270
    },
    {
      "epoch": 3.0,
      "eval_logits/chosen": NaN,
      "eval_logits/rejected": NaN,
      "eval_logps/chosen": NaN,
      "eval_logps/rejected": NaN,
      "eval_loss": NaN,
      "eval_rewards/accuracies": 0.0,
      "eval_rewards/chosen": NaN,
      "eval_rewards/margins": NaN,
      "eval_rewards/rejected": NaN,
      "eval_runtime": 0.7652,
      "eval_samples_per_second": 30.057,
      "eval_steps_per_second": 30.057,
      "step": 276
    },
    {
      "epoch": 3.0434782608695654,
      "grad_norm": NaN,
      "learning_rate": 3.4836956521739133e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 280
    },
    {
      "epoch": 3.1521739130434785,
      "grad_norm": NaN,
      "learning_rate": 3.429347826086957e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 290
    },
    {
      "epoch": 3.260869565217391,
      "grad_norm": NaN,
      "learning_rate": 3.3750000000000003e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 300
    },
    {
      "epoch": 3.369565217391304,
      "grad_norm": NaN,
      "learning_rate": 3.3206521739130438e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 310
    },
    {
      "epoch": 3.4782608695652173,
      "grad_norm": NaN,
      "learning_rate": 3.266304347826087e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 320
    },
    {
      "epoch": 3.5869565217391304,
      "grad_norm": NaN,
      "learning_rate": 3.2119565217391307e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 330
    },
    {
      "epoch": 3.6956521739130435,
      "grad_norm": NaN,
      "learning_rate": 3.157608695652174e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 340
    },
    {
      "epoch": 3.8043478260869565,
      "grad_norm": NaN,
      "learning_rate": 3.1032608695652177e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 350
    },
    {
      "epoch": 3.9130434782608696,
      "grad_norm": NaN,
      "learning_rate": 3.048913043478261e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 360
    },
    {
      "epoch": 4.0,
      "eval_logits/chosen": NaN,
      "eval_logits/rejected": NaN,
      "eval_logps/chosen": NaN,
      "eval_logps/rejected": NaN,
      "eval_loss": NaN,
      "eval_rewards/accuracies": 0.0,
      "eval_rewards/chosen": NaN,
      "eval_rewards/margins": NaN,
      "eval_rewards/rejected": NaN,
      "eval_runtime": 0.7763,
      "eval_samples_per_second": 29.629,
      "eval_steps_per_second": 29.629,
      "step": 368
    },
    {
      "epoch": 4.021739130434782,
      "grad_norm": NaN,
      "learning_rate": 2.9945652173913047e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 370
    },
    {
      "epoch": 4.130434782608695,
      "grad_norm": NaN,
      "learning_rate": 2.940217391304348e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 380
    },
    {
      "epoch": 4.239130434782608,
      "grad_norm": NaN,
      "learning_rate": 2.8858695652173916e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 390
    },
    {
      "epoch": 4.3478260869565215,
      "grad_norm": NaN,
      "learning_rate": 2.831521739130435e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 400
    },
    {
      "epoch": 4.456521739130435,
      "grad_norm": NaN,
      "learning_rate": 2.777173913043478e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 410
    },
    {
      "epoch": 4.565217391304348,
      "grad_norm": NaN,
      "learning_rate": 2.722826086956522e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 420
    },
    {
      "epoch": 4.673913043478261,
      "grad_norm": NaN,
      "learning_rate": 2.668478260869565e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 430
    },
    {
      "epoch": 4.782608695652174,
      "grad_norm": NaN,
      "learning_rate": 2.614130434782609e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 440
    },
    {
      "epoch": 4.891304347826087,
      "grad_norm": NaN,
      "learning_rate": 2.559782608695652e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 450
    },
    {
      "epoch": 5.0,
      "grad_norm": NaN,
      "learning_rate": 2.505434782608696e-06,
      "logits/chosen": NaN,
      "logits/rejected": NaN,
      "logps/chosen": NaN,
      "logps/rejected": NaN,
      "loss": 0.0,
      "rewards/accuracies": 0.0,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 460
    },
    {
      "epoch": 5.0,
      "eval_logits/chosen": NaN,
      "eval_logits/rejected": NaN,
      "eval_logps/chosen": NaN,
      "eval_logps/rejected": NaN,
      "eval_loss": NaN,
      "eval_rewards/accuracies": 0.0,
      "eval_rewards/chosen": NaN,
      "eval_rewards/margins": NaN,
      "eval_rewards/rejected": NaN,
      "eval_runtime": 0.7323,
      "eval_samples_per_second": 31.408,
      "eval_steps_per_second": 31.408,
      "step": 460
    }
  ],
  "logging_steps": 10,
  "max_steps": 920,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 2,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
