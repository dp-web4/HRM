{
  "session": 122,
  "timestamp": "2025-12-27T02:00:50.908812+00:00",
  "description": "State-aware memory consolidation",
  "statistics": {
    "total_encoded": 9,
    "total_consolidated": 8,
    "in_buffer": 1,
    "by_state": {
      "wake": {
        "count": 4,
        "avg_quality": 0.6538430915244164,
        "max_quality": 0.7910762600983502,
        "min_quality": 0.29193914066861926
      },
      "focus": {
        "count": 2,
        "avg_quality": 0.4793271056648214,
        "max_quality": 0.510446620396465,
        "min_quality": 0.4482075909331777
      },
      "dream": {
        "count": 2,
        "avg_quality": 1.0,
        "max_quality": 1.0,
        "min_quality": 1.0
      }
    },
    "consolidation_events": 4
  },
  "consolidation_history": [
    {
      "state": "wake",
      "multiplier": 1.0,
      "consolidated_count": 2,
      "avg_quality": 0.7661784826653482,
      "memories": [
        {
          "content": "Backpropagation algorithm",
          "quality": 0.7844455606490423,
          "state": "wake"
        },
        {
          "content": "Neural networks basics",
          "quality": 0.7479114046816541,
          "state": "wake"
        }
      ]
    },
    {
      "state": "focus",
      "multiplier": 0.5,
      "consolidated_count": 2,
      "avg_quality": 0.4793271056648214,
      "memories": [
        {
          "content": "Transformer architecture",
          "quality": 0.510446620396465,
          "state": "focus"
        },
        {
          "content": "Advanced gradient descent",
          "quality": 0.4482075909331777,
          "state": "focus"
        }
      ]
    },
    {
      "state": "wake",
      "multiplier": 1.0,
      "consolidated_count": 2,
      "avg_quality": 0.5415077003834847,
      "memories": [
        {
          "content": "Attention mechanism details",
          "quality": 0.7910762600983502,
          "state": "wake"
        },
        {
          "content": "Coffee break conversation",
          "quality": 0.29193914066861926,
          "state": "wake"
        }
      ]
    },
    {
      "state": "dream",
      "multiplier": 2.0,
      "consolidated_count": 2,
      "avg_quality": 1.0,
      "memories": [
        {
          "content": "Pattern connections",
          "quality": 1.0,
          "state": "dream"
        },
        {
          "content": "Day's learning synthesis",
          "quality": 1.0,
          "state": "dream"
        }
      ]
    }
  ],
  "consolidated_memories": [
    {
      "content": "Backpropagation algorithm",
      "salience": 0.8,
      "quality": 0.7844455606490423,
      "state": "wake"
    },
    {
      "content": "Neural networks basics",
      "salience": 0.7,
      "quality": 0.7479114046816541,
      "state": "wake"
    },
    {
      "content": "Transformer architecture",
      "salience": 0.95,
      "quality": 0.510446620396465,
      "state": "focus"
    },
    {
      "content": "Advanced gradient descent",
      "salience": 0.9,
      "quality": 0.4482075909331777,
      "state": "focus"
    },
    {
      "content": "Attention mechanism details",
      "salience": 0.85,
      "quality": 0.7910762600983502,
      "state": "wake"
    },
    {
      "content": "Coffee break conversation",
      "salience": 0.3,
      "quality": 0.29193914066861926,
      "state": "wake"
    },
    {
      "content": "Pattern connections",
      "salience": 0.8,
      "quality": 1.0,
      "state": "dream"
    },
    {
      "content": "Day's learning synthesis",
      "salience": 0.75,
      "quality": 1.0,
      "state": "dream"
    }
  ]
}